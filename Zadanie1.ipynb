{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8c8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "np.set_printoptions(threshold=np.inf, suppress=True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d1fad",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af29b5",
   "metadata": {},
   "source": [
    "Dataset obsahuje 60 continues features a jeden predicate (R/M), ktorý vraví o tom, či sa jedná o kameň alebo mínu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399516fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9   ...      51      52      53      54      55      56      57  \\\n",
      "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
      "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "\n",
      "       58      59  60  \n",
      "0  0.0090  0.0032   R  \n",
      "1  0.0052  0.0044   R  \n",
      "2  0.0095  0.0078   R  \n",
      "3  0.0040  0.0117   R  \n",
      "4  0.0107  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "(208, 61)\n",
      "M    111\n",
      "R     97\n",
      "Name: 60, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sonar_data = pd.read_csv('dataset/sonar.all-data', header=None)\n",
    "print(sonar_data.head())\n",
    "print(sonar_data.shape)\n",
    "print(sonar_data[60].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1be166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef90e2",
   "metadata": {},
   "source": [
    "Vykonanie encodingu, kde mínu zakódujeme ako 1 a kameň ako 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fd4bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   0  \n",
       "1  0.0052  0.0044   0  \n",
       "2  0.0095  0.0078   0  \n",
       "3  0.0040  0.0117   0  \n",
       "4  0.0107  0.0094   0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacnutie R za 0 a M za 1\n",
    "# R - Rock M - Mina\n",
    "sonar_data[60] = sonar_data[60].replace(['R', 'M'], [0, 1])\n",
    "sonar_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90d065",
   "metadata": {},
   "source": [
    "Data normalization\n",
    "\n",
    "Data, ktoré používame normalizujeme pomocou standard scaleru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fefc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.399551</td>\n",
       "      <td>-0.040648</td>\n",
       "      <td>-0.026926</td>\n",
       "      <td>-0.715105</td>\n",
       "      <td>0.364456</td>\n",
       "      <td>-0.101253</td>\n",
       "      <td>0.521638</td>\n",
       "      <td>0.297843</td>\n",
       "      <td>1.125272</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.115432</td>\n",
       "      <td>-0.597604</td>\n",
       "      <td>0.680897</td>\n",
       "      <td>-0.295646</td>\n",
       "      <td>1.481635</td>\n",
       "      <td>1.763784</td>\n",
       "      <td>0.069870</td>\n",
       "      <td>0.171678</td>\n",
       "      <td>-0.658947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703538</td>\n",
       "      <td>0.421630</td>\n",
       "      <td>1.055618</td>\n",
       "      <td>0.323330</td>\n",
       "      <td>0.777676</td>\n",
       "      <td>2.607217</td>\n",
       "      <td>1.522625</td>\n",
       "      <td>2.510982</td>\n",
       "      <td>1.318325</td>\n",
       "      <td>0.588706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522349</td>\n",
       "      <td>-0.256857</td>\n",
       "      <td>-0.843151</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>1.901046</td>\n",
       "      <td>1.070732</td>\n",
       "      <td>-0.472406</td>\n",
       "      <td>-0.444554</td>\n",
       "      <td>-0.419852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.129229</td>\n",
       "      <td>0.601067</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.172176</td>\n",
       "      <td>0.400545</td>\n",
       "      <td>2.093337</td>\n",
       "      <td>1.968770</td>\n",
       "      <td>2.852370</td>\n",
       "      <td>3.232767</td>\n",
       "      <td>3.066105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017585</td>\n",
       "      <td>0.836373</td>\n",
       "      <td>-0.197833</td>\n",
       "      <td>1.231812</td>\n",
       "      <td>2.827246</td>\n",
       "      <td>4.120162</td>\n",
       "      <td>1.309360</td>\n",
       "      <td>0.252761</td>\n",
       "      <td>0.257582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.835555</td>\n",
       "      <td>-0.648910</td>\n",
       "      <td>0.481740</td>\n",
       "      <td>-0.719414</td>\n",
       "      <td>-0.987079</td>\n",
       "      <td>-1.149364</td>\n",
       "      <td>-0.193816</td>\n",
       "      <td>-0.084747</td>\n",
       "      <td>-1.000852</td>\n",
       "      <td>-0.610469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137365</td>\n",
       "      <td>-1.009341</td>\n",
       "      <td>0.557326</td>\n",
       "      <td>-0.111785</td>\n",
       "      <td>-0.161060</td>\n",
       "      <td>-0.488635</td>\n",
       "      <td>-0.549875</td>\n",
       "      <td>-0.639154</td>\n",
       "      <td>1.034640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.050790</td>\n",
       "      <td>0.856537</td>\n",
       "      <td>0.111327</td>\n",
       "      <td>-0.312227</td>\n",
       "      <td>-0.292365</td>\n",
       "      <td>-0.672796</td>\n",
       "      <td>-0.013735</td>\n",
       "      <td>1.317299</td>\n",
       "      <td>1.510531</td>\n",
       "      <td>1.772220</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.073812</td>\n",
       "      <td>-0.753780</td>\n",
       "      <td>-0.060532</td>\n",
       "      <td>0.241793</td>\n",
       "      <td>-1.174638</td>\n",
       "      <td>-0.107456</td>\n",
       "      <td>-0.487900</td>\n",
       "      <td>0.447361</td>\n",
       "      <td>0.576375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.456232</td>\n",
       "      <td>-0.116681</td>\n",
       "      <td>-0.705146</td>\n",
       "      <td>-0.779738</td>\n",
       "      <td>-0.647842</td>\n",
       "      <td>0.990954</td>\n",
       "      <td>1.314965</td>\n",
       "      <td>0.407323</td>\n",
       "      <td>0.463980</td>\n",
       "      <td>0.448504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189390</td>\n",
       "      <td>-0.129077</td>\n",
       "      <td>1.230104</td>\n",
       "      <td>-0.847228</td>\n",
       "      <td>0.328253</td>\n",
       "      <td>-0.228741</td>\n",
       "      <td>0.550172</td>\n",
       "      <td>1.841992</td>\n",
       "      <td>1.831621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.136733</td>\n",
       "      <td>-0.861801</td>\n",
       "      <td>-0.366036</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>-0.148740</td>\n",
       "      <td>-0.369029</td>\n",
       "      <td>-0.388465</td>\n",
       "      <td>-0.635067</td>\n",
       "      <td>0.053253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761663</td>\n",
       "      <td>-0.200066</td>\n",
       "      <td>0.351373</td>\n",
       "      <td>-0.422934</td>\n",
       "      <td>-0.335815</td>\n",
       "      <td>-0.765856</td>\n",
       "      <td>-0.735798</td>\n",
       "      <td>-0.282388</td>\n",
       "      <td>0.038412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.004381</td>\n",
       "      <td>0.160078</td>\n",
       "      <td>-0.673843</td>\n",
       "      <td>-0.531979</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.212502</td>\n",
       "      <td>0.064137</td>\n",
       "      <td>-0.200113</td>\n",
       "      <td>-0.442014</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268428</td>\n",
       "      <td>-1.108725</td>\n",
       "      <td>-0.801960</td>\n",
       "      <td>-0.437077</td>\n",
       "      <td>0.118548</td>\n",
       "      <td>1.070732</td>\n",
       "      <td>0.906526</td>\n",
       "      <td>-0.039138</td>\n",
       "      <td>-0.678871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.049533</td>\n",
       "      <td>-0.095392</td>\n",
       "      <td>0.134804</td>\n",
       "      <td>0.148821</td>\n",
       "      <td>-1.055648</td>\n",
       "      <td>0.522865</td>\n",
       "      <td>0.401585</td>\n",
       "      <td>-0.264859</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.202404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501539</td>\n",
       "      <td>-0.867363</td>\n",
       "      <td>0.227802</td>\n",
       "      <td>-0.804798</td>\n",
       "      <td>-0.825128</td>\n",
       "      <td>-0.765856</td>\n",
       "      <td>-0.007598</td>\n",
       "      <td>-0.704020</td>\n",
       "      <td>-0.340154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.137949</td>\n",
       "      <td>-0.064979</td>\n",
       "      <td>-0.788619</td>\n",
       "      <td>-0.575067</td>\n",
       "      <td>-0.970839</td>\n",
       "      <td>-1.200244</td>\n",
       "      <td>-0.912514</td>\n",
       "      <td>0.061226</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.202404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122759</td>\n",
       "      <td>0.311055</td>\n",
       "      <td>-0.856881</td>\n",
       "      <td>-0.762369</td>\n",
       "      <td>-0.370766</td>\n",
       "      <td>-0.661898</td>\n",
       "      <td>-0.673823</td>\n",
       "      <td>-0.298604</td>\n",
       "      <td>0.994790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.399551 -0.040648 -0.026926 -0.715105  0.364456 -0.101253  0.521638   \n",
       "1    0.703538  0.421630  1.055618  0.323330  0.777676  2.607217  1.522625   \n",
       "2   -0.129229  0.601067  1.723404  1.172176  0.400545  2.093337  1.968770   \n",
       "3   -0.835555 -0.648910  0.481740 -0.719414 -0.987079 -1.149364 -0.193816   \n",
       "4    2.050790  0.856537  0.111327 -0.312227 -0.292365 -0.672796 -0.013735   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "203 -0.456232 -0.116681 -0.705146 -0.779738 -0.647842  0.990954  1.314965   \n",
       "204  0.136733 -0.861801 -0.366036  0.054026  0.014392 -0.148740 -0.369029   \n",
       "205  1.004381  0.160078 -0.673843 -0.531979 -0.723629  0.212502  0.064137   \n",
       "206  0.049533 -0.095392  0.134804  0.148821 -1.055648  0.522865  0.401585   \n",
       "207 -0.137949 -0.064979 -0.788619 -0.575067 -0.970839 -1.200244 -0.912514   \n",
       "\n",
       "           7         8         9   ...        51        52        53  \\\n",
       "0    0.297843  1.125272  0.021186  ... -1.115432 -0.597604  0.680897   \n",
       "1    2.510982  1.318325  0.588706  ... -0.522349 -0.256857 -0.843151   \n",
       "2    2.852370  3.232767  3.066105  ...  1.017585  0.836373 -0.197833   \n",
       "3   -0.084747 -1.000852 -0.610469  ... -0.137365 -1.009341  0.557326   \n",
       "4    1.317299  1.510531  1.772220  ... -1.073812 -0.753780 -0.060532   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "203  0.407323  0.463980  0.448504  ... -0.189390 -0.129077  1.230104   \n",
       "204 -0.388465 -0.635067  0.053253  ... -0.761663 -0.200066  0.351373   \n",
       "205 -0.200113 -0.442014  0.332912  ...  0.268428 -1.108725 -0.801960   \n",
       "206 -0.264859  0.139685  0.202404  ... -0.501539 -0.867363  0.227802   \n",
       "207  0.061226  0.053319  0.202404  ...  0.122759  0.311055 -0.856881   \n",
       "\n",
       "           54        55        56        57        58        59  60  \n",
       "0   -0.295646  1.481635  1.763784  0.069870  0.171678 -0.658947   0  \n",
       "1    0.015503  1.901046  1.070732 -0.472406 -0.444554 -0.419852   0  \n",
       "2    1.231812  2.827246  4.120162  1.309360  0.252761  0.257582   0  \n",
       "3   -0.111785 -0.161060 -0.488635 -0.549875 -0.639154  1.034640   0  \n",
       "4    0.241793 -1.174638 -0.107456 -0.487900  0.447361  0.576375   0  \n",
       "..        ...       ...       ...       ...       ...       ...  ..  \n",
       "203 -0.847228  0.328253 -0.228741  0.550172  1.841992  1.831621   1  \n",
       "204 -0.422934 -0.335815 -0.765856 -0.735798 -0.282388  0.038412   1  \n",
       "205 -0.437077  0.118548  1.070732  0.906526 -0.039138 -0.678871   1  \n",
       "206 -0.804798 -0.825128 -0.765856 -0.007598 -0.704020 -0.340154   1  \n",
       "207 -0.762369 -0.370766 -0.661898 -0.673823 -0.298604  0.994790   1  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_dfMinMax = sonar_data.copy()\n",
    "for x in range(60):\n",
    "    normalized_dfMinMax[x] = MinMaxScaler().fit_transform(np.array(normalized_dfMinMax[x]).reshape(-1,1))\n",
    "\n",
    "normalized_dfMinMax\n",
    "\n",
    "normalized_df = sonar_data.copy()\n",
    "for x in range(60):\n",
    "    normalized_df[x] = StandardScaler().fit_transform(np.array(normalized_df[x]).reshape(-1,1))\n",
    "\n",
    "normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb29279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.708035e-17</td>\n",
       "      <td>6.832142e-17</td>\n",
       "      <td>-1.195625e-16</td>\n",
       "      <td>1.622634e-16</td>\n",
       "      <td>-1.793437e-16</td>\n",
       "      <td>2.049643e-16</td>\n",
       "      <td>1.024821e-16</td>\n",
       "      <td>3.416071e-17</td>\n",
       "      <td>-3.757678e-16</td>\n",
       "      <td>3.416071e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024821e-16</td>\n",
       "      <td>3.416071e-17</td>\n",
       "      <td>-1.451830e-16</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>-2.391250e-16</td>\n",
       "      <td>3.416071e-17</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>1.345078e-16</td>\n",
       "      <td>7.686159e-17</td>\n",
       "      <td>0.533654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.206158e+00</td>\n",
       "      <td>-1.150725e+00</td>\n",
       "      <td>-1.104253e+00</td>\n",
       "      <td>-1.036115e+00</td>\n",
       "      <td>-1.236093e+00</td>\n",
       "      <td>-1.600493e+00</td>\n",
       "      <td>-1.921613e+00</td>\n",
       "      <td>-1.522110e+00</td>\n",
       "      <td>-1.443689e+00</td>\n",
       "      <td>-1.468833e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.313126e+00</td>\n",
       "      <td>-1.449472e+00</td>\n",
       "      <td>-1.364897e+00</td>\n",
       "      <td>-1.229092e+00</td>\n",
       "      <td>-1.366868e+00</td>\n",
       "      <td>-1.302971e+00</td>\n",
       "      <td>-1.185113e+00</td>\n",
       "      <td>-1.271603e+00</td>\n",
       "      <td>-1.176985e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.894939e-01</td>\n",
       "      <td>-6.686781e-01</td>\n",
       "      <td>-6.490624e-01</td>\n",
       "      <td>-6.359298e-01</td>\n",
       "      <td>-6.703975e-01</td>\n",
       "      <td>-6.367565e-01</td>\n",
       "      <td>-6.626732e-01</td>\n",
       "      <td>-6.400918e-01</td>\n",
       "      <td>-6.856590e-01</td>\n",
       "      <td>-7.232644e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.394049e-01</td>\n",
       "      <td>-7.999231e-01</td>\n",
       "      <td>-7.642025e-01</td>\n",
       "      <td>-7.270112e-01</td>\n",
       "      <td>-6.678488e-01</td>\n",
       "      <td>-7.138771e-01</td>\n",
       "      <td>-6.738235e-01</td>\n",
       "      <td>-6.918580e-01</td>\n",
       "      <td>-6.788714e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.774703e-01</td>\n",
       "      <td>-2.322506e-01</td>\n",
       "      <td>-2.486515e-01</td>\n",
       "      <td>-2.120457e-01</td>\n",
       "      <td>-2.292089e-01</td>\n",
       "      <td>-2.106432e-01</td>\n",
       "      <td>-2.400524e-01</td>\n",
       "      <td>-2.672134e-01</td>\n",
       "      <td>-2.180558e-01</td>\n",
       "      <td>-1.928459e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.102002e-01</td>\n",
       "      <td>-1.645716e-01</td>\n",
       "      <td>-2.252935e-01</td>\n",
       "      <td>-2.532164e-01</td>\n",
       "      <td>-2.396997e-01</td>\n",
       "      <td>-3.240352e-01</td>\n",
       "      <td>-3.329639e-01</td>\n",
       "      <td>-2.499546e-01</td>\n",
       "      <td>-2.405314e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.784345e-01</td>\n",
       "      <td>2.893335e-01</td>\n",
       "      <td>3.682681e-01</td>\n",
       "      <td>2.285353e-01</td>\n",
       "      <td>4.524231e-01</td>\n",
       "      <td>5.012417e-01</td>\n",
       "      <td>5.232608e-01</td>\n",
       "      <td>4.096773e-01</td>\n",
       "      <td>4.692723e-01</td>\n",
       "      <td>4.507410e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.438640e-01</td>\n",
       "      <td>5.950106e-01</td>\n",
       "      <td>4.886751e-01</td>\n",
       "      <td>3.973675e-01</td>\n",
       "      <td>4.112618e-01</td>\n",
       "      <td>4.513169e-01</td>\n",
       "      <td>3.719959e-01</td>\n",
       "      <td>3.865486e-01</td>\n",
       "      <td>4.020352e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.706053e+00</td>\n",
       "      <td>5.944643e+00</td>\n",
       "      <td>6.836142e+00</td>\n",
       "      <td>8.025419e+00</td>\n",
       "      <td>5.878863e+00</td>\n",
       "      <td>4.710224e+00</td>\n",
       "      <td>4.074573e+00</td>\n",
       "      <td>3.816498e+00</td>\n",
       "      <td>4.274237e+00</td>\n",
       "      <td>3.746234e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.980752e+00</td>\n",
       "      <td>4.016680e+00</td>\n",
       "      <td>3.330819e+00</td>\n",
       "      <td>5.008027e+00</td>\n",
       "      <td>5.448568e+00</td>\n",
       "      <td>4.795888e+00</td>\n",
       "      <td>5.585599e+00</td>\n",
       "      <td>4.615037e+00</td>\n",
       "      <td>7.450343e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02   \n",
       "mean   1.708035e-17  6.832142e-17 -1.195625e-16  1.622634e-16 -1.793437e-16   \n",
       "std    1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00   \n",
       "min   -1.206158e+00 -1.150725e+00 -1.104253e+00 -1.036115e+00 -1.236093e+00   \n",
       "25%   -6.894939e-01 -6.686781e-01 -6.490624e-01 -6.359298e-01 -6.703975e-01   \n",
       "50%   -2.774703e-01 -2.322506e-01 -2.486515e-01 -2.120457e-01 -2.292089e-01   \n",
       "75%    2.784345e-01  2.893335e-01  3.682681e-01  2.285353e-01  4.524231e-01   \n",
       "max    4.706053e+00  5.944643e+00  6.836142e+00  8.025419e+00  5.878863e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02   \n",
       "mean   2.049643e-16  1.024821e-16  3.416071e-17 -3.757678e-16  3.416071e-17   \n",
       "std    1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00   \n",
       "min   -1.600493e+00 -1.921613e+00 -1.522110e+00 -1.443689e+00 -1.468833e+00   \n",
       "25%   -6.367565e-01 -6.626732e-01 -6.400918e-01 -6.856590e-01 -7.232644e-01   \n",
       "50%   -2.106432e-01 -2.400524e-01 -2.672134e-01 -2.180558e-01 -1.928459e-01   \n",
       "75%    5.012417e-01  5.232608e-01  4.096773e-01  4.692723e-01  4.507410e-01   \n",
       "max    4.710224e+00  4.074573e+00  3.816498e+00  4.274237e+00  3.746234e+00   \n",
       "\n",
       "       ...            51            52            53            54  \\\n",
       "count  ...  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02   \n",
       "mean   ...  1.024821e-16  3.416071e-17 -1.451830e-16  2.775558e-17   \n",
       "std    ...  1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00   \n",
       "min    ... -1.313126e+00 -1.449472e+00 -1.364897e+00 -1.229092e+00   \n",
       "25%    ... -6.394049e-01 -7.999231e-01 -7.642025e-01 -7.270112e-01   \n",
       "50%    ... -2.102002e-01 -1.645716e-01 -2.252935e-01 -2.532164e-01   \n",
       "75%    ...  3.438640e-01  5.950106e-01  4.886751e-01  3.973675e-01   \n",
       "max    ...  5.980752e+00  4.016680e+00  3.330819e+00  5.008027e+00   \n",
       "\n",
       "                 55            56            57            58            59  \\\n",
       "count  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02   \n",
       "mean  -2.391250e-16  3.416071e-17 -1.110223e-16  1.345078e-16  7.686159e-17   \n",
       "std    1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00   \n",
       "min   -1.366868e+00 -1.302971e+00 -1.185113e+00 -1.271603e+00 -1.176985e+00   \n",
       "25%   -6.678488e-01 -7.138771e-01 -6.738235e-01 -6.918580e-01 -6.788714e-01   \n",
       "50%   -2.396997e-01 -3.240352e-01 -3.329639e-01 -2.499546e-01 -2.405314e-01   \n",
       "75%    4.112618e-01  4.513169e-01  3.719959e-01  3.865486e-01  4.020352e-01   \n",
       "max    5.448568e+00  4.795888e+00  5.585599e+00  4.615037e+00  7.450343e+00   \n",
       "\n",
       "               60  \n",
       "count  208.000000  \n",
       "mean     0.533654  \n",
       "std      0.500070  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280fd150",
   "metadata": {},
   "source": [
    "Train test val split 80/10/10\n",
    "\n",
    "Dáta delíme takto kvôli menšiemu počtu dostupných vzoriek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f752c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalized_df.drop(columns=60, axis=1)\n",
    "y = normalized_df[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebe8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb690bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166, 60)\n",
      "1    91\n",
      "0    75\n",
      "Name: 60, dtype: int64\n",
      "******\n",
      "(21, 60)\n",
      "1    11\n",
      "0    10\n",
      "Name: 60, dtype: int64\n",
      "******\n",
      "(21, 60)\n",
      "0    12\n",
      "1     9\n",
      "Name: 60, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.value_counts())\n",
    "print('******')\n",
    "print(X_test.shape)\n",
    "print(y_test.value_counts())\n",
    "print('******')\n",
    "print(X_val.shape)\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc608bc5",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbd99f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 15:34:25.490127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1b105",
   "metadata": {},
   "source": [
    "Vytvorenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4165d",
   "metadata": {},
   "source": [
    "V rámci tensorflow časti vytvárame 5 rôznych modelov\n",
    "\n",
    "Všetky majú rovnakú architektúru, len sa líšia v metódach použitých pri riešení problému overfittingu. Máme vstupnú vrstvu so 16 neuronmi, dve skryté vrstvy s 16 neurónmi a nakoniec výstupnú vrstvu s jedným neurónom.\n",
    "\n",
    "Pri všetkých vrstvách používame aktivačnú funkciu ReLu až na poslednú, kde používame sigmoid.\n",
    "\n",
    "Model 1 nepoužíva žiadnu metódu prevencie overfittingu\n",
    "\n",
    "Model 2 používa metódu dropout, kde sme ako šancu vypadnuta neurónu dali 50%, dropout sa vykonáva pri prvej a druhej skrytej vrstve.\n",
    "\n",
    "Model 3 používa early stopping, riadi sa podľa val_loss a parameter patience sme nastavili na 10 epoch.\n",
    "\n",
    "Model 4 používa regularizáciu, ako hodnotu parametrov l1 a l2 sme zvolili hodnotu 0,005. Skúsili sme použiť aj vyššie hodnoty ale to viedlo k oveľa horším výsledkom, kde napríklad acc padlo približne na 55%.\n",
    "\n",
    "Model 5 sme skúsili otestovať ako sa bude NN správať ak použijeme naraz dropout a early stopping, parametre sme použili rovnaké ako pri predchádzajúcich modeloch.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4021b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 15:35:06.495299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#nothing\n",
    "tf_model1 = Sequential()\n",
    "tf_model1.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns)))\n",
    "tf_model1.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model1.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model1.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "#dropout\n",
    "tf_model2 = Sequential()\n",
    "tf_model2.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns)))\n",
    "tf_model2.add(Dropout(0.5))\n",
    "tf_model2.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model2.add(Dropout(0.5))\n",
    "tf_model2.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model2.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "#early stopping\n",
    "tf_model3 = Sequential()\n",
    "tf_model3.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns)))\n",
    "tf_model3.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model3.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model3.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "#regularization\n",
    "tf_model4 = Sequential()\n",
    "tf_model4.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns), kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.005)))\n",
    "tf_model4.add(Dense(16, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.005)))\n",
    "tf_model4.add(Dense(16, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.005)))\n",
    "tf_model4.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "#dropout + earlystop\n",
    "tf_model5 = Sequential()\n",
    "tf_model5.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns)))\n",
    "tf_model5.add(Dropout(0.5))\n",
    "tf_model5.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model5.add(Dropout(0.5))\n",
    "tf_model5.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model5.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f31a8",
   "metadata": {},
   "source": [
    "Ako loss funkciu sme zvolili binary crossentropy a ako optimizer Adam.\n",
    "\n",
    "Na sledovanie NN sme vybrali 4 metriky Acc, MSE, precision a recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a04d45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "tf_model1.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])\n",
    "tf_model2.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])\n",
    "tf_model3.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])\n",
    "tf_model4.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])\n",
    "tf_model5.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d93102",
   "metadata": {},
   "source": [
    "Batch size sme zvolili na 16.\n",
    "\n",
    "Počet epoch trénovania sme zvolili 100, pri tomto zadaní by mal postačovať aj menší počet epoch ale kvôli krátkemu času behu sme nechali 100 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a713898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(model, name, callbackArg):\n",
    "    \n",
    "    model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callbackArg\n",
    "    )\n",
    "\n",
    "    model.save('./'+ name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86c6af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "\n",
    "w = wandb.init(project='zadanie1',reinit=True)\n",
    "w.config.epochs = 100\n",
    "w.config.batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "fitModel(tf_model1, 'model1', [WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1723e113",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitModel(tf_model2, 'model2', [WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeae49d-6d71-4b0d-a424-5ce39c795baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.finish()\n",
    "w = wandb.init(project='zadanie1',reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0e13f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitModel(tf_model3, 'model3', [earlyStop,WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5b5af-f3f2-42bd-8c22-ad6e6cfd1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.finish()\n",
    "w = wandb.init(project='zadanie1',reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad287c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitModel(tf_model4, 'model4', [WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6037c60-6807-4eaa-9e02-376155aad2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.finish()\n",
    "w = wandb.init(project='zadanie1',reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0185bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitModel(tf_model5, 'model5', [earlyStop,WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd8295-bc9d-4d28-a931-cf32642fef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.finish()\n",
    "w = wandb.init(project='zadanie1',reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2085f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pomocna funkcia\n",
    "def predictEval(tf_model, XX, yy):\n",
    "    # vykonanie predikcie\n",
    "    y_pred = tf_model.predict(XX)\n",
    "    # uprava outputu na boolean\n",
    "    y_pred_bool = np.copy(y_pred)\n",
    "    for x in y_pred_bool:\n",
    "        x[0] = round(x[0])\n",
    "    y_pred_bool\n",
    "\n",
    "    #vratenie y a accuaracy\n",
    "    return [y_pred, y_pred_bool, accuracy_score(y_pred_bool, yy), mean_squared_error(y_pred_bool, yy), precision_score(y_pred_bool, yy), recall_score(y_pred_bool, yy)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ac23f",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56957029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictEvalWrap(model, name):\n",
    "    train = predictEval(model, X_train, y_train)\n",
    "    val = predictEval(model, X_val, y_val)\n",
    "    test = predictEval(model, X_test, y_test)\n",
    "\n",
    "    print(name)\n",
    "    print('Accuracy score')\n",
    "    print(f'Train: {train[2]*100:.2f}%')\n",
    "    print(f'Val: {val[2]*100:.2f}%')\n",
    "    print(f'Test: {test[2]*100:.2f}%')\n",
    "    print('Mean squared error')\n",
    "    print(f'Train: {train[3]*100:.2f}%')\n",
    "    print(f'Val: {val[3]*100:.2f}%')\n",
    "    print(f'Test: {test[3]*100:.2f}%')\n",
    "    print('Precision')\n",
    "    print(f'Train: {train[4]*100:.2f}%')\n",
    "    print(f'Val: {val[4]*100:.2f}%')\n",
    "    print(f'Test: {test[4]*100:.2f}%')\n",
    "    print('Recall')\n",
    "    print(f'Train: {train[5]*100:.2f}%')\n",
    "    print(f'Val: {val[5]*100:.2f}%')\n",
    "    print(f'Test: {test[5]*100:.2f}%')\n",
    "    print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictEvalWrap(tf_model1, 'No overfit prevention')\n",
    "predictEvalWrap(tf_model2, 'Dropout')\n",
    "predictEvalWrap(tf_model3, 'Early stopping')\n",
    "predictEvalWrap(tf_model4, 'Regularization')\n",
    "predictEvalWrap(tf_model5, 'Dropout + Early stopping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ca97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V rámci pytorch časti vytvárame 3 rôzne modely\n",
    "\n",
    "Všetky modely majú rovnakú architektúru, ktorá sa líši iba v metódach použitých pri riešení problému overfittingu. Vstupná vrstva má 16 neurónov, nasledovaná dvoma skrytými vrstvami s 16 neurónmi a nakoniec výstupná vrstva s jedným neurónom.\n",
    "\n",
    "Všetky vrstvy používajú aktivačnú funkciu ReLu okrem poslednej, kde sa používa sigmoid.\n",
    "\n",
    "Model 1 nepoužíva žiadnu metódu prevencie overfittingu.\n",
    "\n",
    "Model 2 používa metódu dropout, kde sme ako pravdepodobnosť vypadnutia neurónov zvolili 50%. Dropout sa aplikuje na prvú a druhú skrytú vrstvu.\n",
    "\n",
    "Model 3 používa metódu early stopping, ktorá sa riadi podľa val_loss a parameter patience je nastavený na 10 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a688b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PyTorchModel nepoužíva žiadnu metódu prevencie overfittingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch model\n",
    "class PyTorchModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PyTorchModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf283a74",
   "metadata": {},
   "source": [
    "PyTorchModelDropout používa metódu dropout, kde sme ako pravdepodobnosť vypadnutia neurónov zvolili 50%. Dropout sa aplikuje na prvú a druhú skrytú vrstvu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchModelDropout(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.5):\n",
    "        super(PyTorchModelDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 16)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(16, 16)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc3754",
   "metadata": {},
   "source": [
    "Táto trieda datasetu prijíma dva argumenty, X a y, ktoré sú príznaky a lable datasetu.\n",
    "Metóda init() inicializuje dataset tým, že konvertuje príznaky a značky na PyTorch tenzory pomocou funkcie torch.tensor()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b59555",
   "metadata": {},
   "source": [
    "Táto časť vytvára PyTorch datasety a dataloadery pre trénovacie, validačné a testovacie dáta pomocou vlastnej triedy datasetu \"SonarDataset\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SonarDataset(X_train, y_train)\n",
    "val_dataset = SonarDataset(X_val, y_val)\n",
    "test_dataset = SonarDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dee67a",
   "metadata": {},
   "source": [
    "V tejto časti inicializujeme vyššie spomínané modely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06616cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train.columns)\n",
    "model = PyTorchModel(input_dim)\n",
    "model_dropout = PyTorchModelDropout(input_dim, dropout_rate=0.5)\n",
    "model_early_stopping = PyTorchModel(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe9c6e",
   "metadata": {},
   "source": [
    "Ako Loss funkcia sa používa trieda nn.BCELoss() a bude použitá ako stratová funkcia pre všetky tri modely. \n",
    "Ako optimizer sa používa Adam ktorý budú použitý na aktualizáciu váh a sklonov v rámci trénovania modelov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "optimizer_dropout = optim.Adam(model_dropout.parameters())\n",
    "optimizer_early_stopping = optim.Adam(model_early_stopping.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d03d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af21143",
   "metadata": {},
   "source": [
    "Táto časť trénuje model neurónovej siete pomocou trénovacích dát a vyhodnocuje výkon modelu na validačných dátach v každej epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb95f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trenóvanie modelu bez overfittingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9157ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({\"loss\": loss})\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            y_val_pred = model(X_val_batch)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47346fa",
   "metadata": {},
   "source": [
    "Trénovanie modelu s pridaným droupoutom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89725875",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model_dropout.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer_dropout.zero_grad()\n",
    "        y_pred = model_dropout(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_dropout.eval()\n",
    "        val_loss_sum = 0\n",
    "        val_batch_count = 0\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            y_val_pred = model_dropout(X_val_batch)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_loss_sum += val_loss.item()\n",
    "            val_batch_count += 1\n",
    "        val_loss_avg = val_loss_sum / val_batch_count\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6326345",
   "metadata": {},
   "source": [
    "Trénovanie modelu s early stoppage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabdcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_early_stopping.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer_early_stopping.zero_grad()\n",
    "        y_pred = model_early_stopping(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_early_stopping.eval()\n",
    "        val_loss_sum = 0\n",
    "        val_batch_count = 0\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            y_val_pred = model_early_stopping(X_val_batch)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_loss_sum += val_loss.item()\n",
    "            val_batch_count += 1\n",
    "        val_loss_avg = val_loss_sum / val_batch_count\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss_avg:.4f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss_avg < best_val_loss:\n",
    "        best_val_loss = val_loss_avg\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22763ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pomocná funkcia na vyhodnotenie úspešnosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab49a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_eval(model, loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            y_pred_bool = torch.round(y_pred)\n",
    "            accuracy = accuracy_score(y_pred_bool, y_batch)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = predict_eval(model, train_loader)\n",
    "val_accuracy = predict_eval(model, val_loader)\n",
    "test_accuracy = predict_eval(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_dropout = predict_eval(model_dropout, train_loader)\n",
    "val_accuracy_dropout = predict_eval(model_dropout, val_loader)\n",
    "test_accuracy_dropout = predict_eval(model_dropout, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da69398",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_early_stopping = predict_eval(model_early_stopping, train_loader)\n",
    "val_accuracy_early_stopping = predict_eval(model_early_stopping, val_loader)\n",
    "test_accuracy_early_stopping = predict_eval(model_early_stopping, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df66fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No overfit prevention')\n",
    "print(f'Train: {train_accuracy * 100:.2f}%')\n",
    "print(f'Val: {val_accuracy * 100:.2f}%')\n",
    "print(f'Test: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Droupout')\n",
    "print(f'Train: {train_accuracy_dropout * 100:.2f}%')\n",
    "print(f'Val: {val_accuracy_dropout * 100:.2f}%')\n",
    "print(f'Test: {test_accuracy_dropout * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cee445",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Early stopping')\n",
    "print(f'Train: {train_accuracy_early_stopping * 100:.2f}%')\n",
    "print(f'Val: {val_accuracy_early_stopping * 100:.2f}%')\n",
    "print(f'Test: {test_accuracy_early_stopping * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0dc699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161de969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
