{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8c8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "np.set_printoptions(threshold=np.inf, suppress=True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d1fad",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399516fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9   ...      51      52      53      54      55      56      57  \\\n",
      "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
      "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "\n",
      "       58      59  60  \n",
      "0  0.0090  0.0032   R  \n",
      "1  0.0052  0.0044   R  \n",
      "2  0.0095  0.0078   R  \n",
      "3  0.0040  0.0117   R  \n",
      "4  0.0107  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "(208, 61)\n",
      "M    111\n",
      "R     97\n",
      "Name: 60, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sonar_data = pd.read_csv('dataset/sonar.all-data', header=None)\n",
    "print(sonar_data.head())\n",
    "print(sonar_data.shape)\n",
    "print(sonar_data[60].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1be166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fd4bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   0  \n",
       "1  0.0052  0.0044   0  \n",
       "2  0.0095  0.0078   0  \n",
       "3  0.0040  0.0117   0  \n",
       "4  0.0107  0.0094   0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacnutie R za 0 a M za 1\n",
    "# R - Rock M - Mina\n",
    "sonar_data[60] = sonar_data[60].replace(['R', 'M'], [0, 1])\n",
    "sonar_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90d065",
   "metadata": {},
   "source": [
    "Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fefc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.399551</td>\n",
       "      <td>-0.040648</td>\n",
       "      <td>-0.026926</td>\n",
       "      <td>-0.715105</td>\n",
       "      <td>0.364456</td>\n",
       "      <td>-0.101253</td>\n",
       "      <td>0.521638</td>\n",
       "      <td>0.297843</td>\n",
       "      <td>1.125272</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.115432</td>\n",
       "      <td>-0.597604</td>\n",
       "      <td>0.680897</td>\n",
       "      <td>-0.295646</td>\n",
       "      <td>1.481635</td>\n",
       "      <td>1.763784</td>\n",
       "      <td>0.069870</td>\n",
       "      <td>0.171678</td>\n",
       "      <td>-0.658947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703538</td>\n",
       "      <td>0.421630</td>\n",
       "      <td>1.055618</td>\n",
       "      <td>0.323330</td>\n",
       "      <td>0.777676</td>\n",
       "      <td>2.607217</td>\n",
       "      <td>1.522625</td>\n",
       "      <td>2.510982</td>\n",
       "      <td>1.318325</td>\n",
       "      <td>0.588706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522349</td>\n",
       "      <td>-0.256857</td>\n",
       "      <td>-0.843151</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>1.901046</td>\n",
       "      <td>1.070732</td>\n",
       "      <td>-0.472406</td>\n",
       "      <td>-0.444554</td>\n",
       "      <td>-0.419852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.129229</td>\n",
       "      <td>0.601067</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.172176</td>\n",
       "      <td>0.400545</td>\n",
       "      <td>2.093337</td>\n",
       "      <td>1.968770</td>\n",
       "      <td>2.852370</td>\n",
       "      <td>3.232767</td>\n",
       "      <td>3.066105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017585</td>\n",
       "      <td>0.836373</td>\n",
       "      <td>-0.197833</td>\n",
       "      <td>1.231812</td>\n",
       "      <td>2.827246</td>\n",
       "      <td>4.120162</td>\n",
       "      <td>1.309360</td>\n",
       "      <td>0.252761</td>\n",
       "      <td>0.257582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.835555</td>\n",
       "      <td>-0.648910</td>\n",
       "      <td>0.481740</td>\n",
       "      <td>-0.719414</td>\n",
       "      <td>-0.987079</td>\n",
       "      <td>-1.149364</td>\n",
       "      <td>-0.193816</td>\n",
       "      <td>-0.084747</td>\n",
       "      <td>-1.000852</td>\n",
       "      <td>-0.610469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137365</td>\n",
       "      <td>-1.009341</td>\n",
       "      <td>0.557326</td>\n",
       "      <td>-0.111785</td>\n",
       "      <td>-0.161060</td>\n",
       "      <td>-0.488635</td>\n",
       "      <td>-0.549875</td>\n",
       "      <td>-0.639154</td>\n",
       "      <td>1.034640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.050790</td>\n",
       "      <td>0.856537</td>\n",
       "      <td>0.111327</td>\n",
       "      <td>-0.312227</td>\n",
       "      <td>-0.292365</td>\n",
       "      <td>-0.672796</td>\n",
       "      <td>-0.013735</td>\n",
       "      <td>1.317299</td>\n",
       "      <td>1.510531</td>\n",
       "      <td>1.772220</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.073812</td>\n",
       "      <td>-0.753780</td>\n",
       "      <td>-0.060532</td>\n",
       "      <td>0.241793</td>\n",
       "      <td>-1.174638</td>\n",
       "      <td>-0.107456</td>\n",
       "      <td>-0.487900</td>\n",
       "      <td>0.447361</td>\n",
       "      <td>0.576375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.456232</td>\n",
       "      <td>-0.116681</td>\n",
       "      <td>-0.705146</td>\n",
       "      <td>-0.779738</td>\n",
       "      <td>-0.647842</td>\n",
       "      <td>0.990954</td>\n",
       "      <td>1.314965</td>\n",
       "      <td>0.407323</td>\n",
       "      <td>0.463980</td>\n",
       "      <td>0.448504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189390</td>\n",
       "      <td>-0.129077</td>\n",
       "      <td>1.230104</td>\n",
       "      <td>-0.847228</td>\n",
       "      <td>0.328253</td>\n",
       "      <td>-0.228741</td>\n",
       "      <td>0.550172</td>\n",
       "      <td>1.841992</td>\n",
       "      <td>1.831621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.136733</td>\n",
       "      <td>-0.861801</td>\n",
       "      <td>-0.366036</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>-0.148740</td>\n",
       "      <td>-0.369029</td>\n",
       "      <td>-0.388465</td>\n",
       "      <td>-0.635067</td>\n",
       "      <td>0.053253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761663</td>\n",
       "      <td>-0.200066</td>\n",
       "      <td>0.351373</td>\n",
       "      <td>-0.422934</td>\n",
       "      <td>-0.335815</td>\n",
       "      <td>-0.765856</td>\n",
       "      <td>-0.735798</td>\n",
       "      <td>-0.282388</td>\n",
       "      <td>0.038412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.004381</td>\n",
       "      <td>0.160078</td>\n",
       "      <td>-0.673843</td>\n",
       "      <td>-0.531979</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.212502</td>\n",
       "      <td>0.064137</td>\n",
       "      <td>-0.200113</td>\n",
       "      <td>-0.442014</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268428</td>\n",
       "      <td>-1.108725</td>\n",
       "      <td>-0.801960</td>\n",
       "      <td>-0.437077</td>\n",
       "      <td>0.118548</td>\n",
       "      <td>1.070732</td>\n",
       "      <td>0.906526</td>\n",
       "      <td>-0.039138</td>\n",
       "      <td>-0.678871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.049533</td>\n",
       "      <td>-0.095392</td>\n",
       "      <td>0.134804</td>\n",
       "      <td>0.148821</td>\n",
       "      <td>-1.055648</td>\n",
       "      <td>0.522865</td>\n",
       "      <td>0.401585</td>\n",
       "      <td>-0.264859</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.202404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501539</td>\n",
       "      <td>-0.867363</td>\n",
       "      <td>0.227802</td>\n",
       "      <td>-0.804798</td>\n",
       "      <td>-0.825128</td>\n",
       "      <td>-0.765856</td>\n",
       "      <td>-0.007598</td>\n",
       "      <td>-0.704020</td>\n",
       "      <td>-0.340154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.137949</td>\n",
       "      <td>-0.064979</td>\n",
       "      <td>-0.788619</td>\n",
       "      <td>-0.575067</td>\n",
       "      <td>-0.970839</td>\n",
       "      <td>-1.200244</td>\n",
       "      <td>-0.912514</td>\n",
       "      <td>0.061226</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>0.202404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122759</td>\n",
       "      <td>0.311055</td>\n",
       "      <td>-0.856881</td>\n",
       "      <td>-0.762369</td>\n",
       "      <td>-0.370766</td>\n",
       "      <td>-0.661898</td>\n",
       "      <td>-0.673823</td>\n",
       "      <td>-0.298604</td>\n",
       "      <td>0.994790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.399551 -0.040648 -0.026926 -0.715105  0.364456 -0.101253  0.521638   \n",
       "1    0.703538  0.421630  1.055618  0.323330  0.777676  2.607217  1.522625   \n",
       "2   -0.129229  0.601067  1.723404  1.172176  0.400545  2.093337  1.968770   \n",
       "3   -0.835555 -0.648910  0.481740 -0.719414 -0.987079 -1.149364 -0.193816   \n",
       "4    2.050790  0.856537  0.111327 -0.312227 -0.292365 -0.672796 -0.013735   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "203 -0.456232 -0.116681 -0.705146 -0.779738 -0.647842  0.990954  1.314965   \n",
       "204  0.136733 -0.861801 -0.366036  0.054026  0.014392 -0.148740 -0.369029   \n",
       "205  1.004381  0.160078 -0.673843 -0.531979 -0.723629  0.212502  0.064137   \n",
       "206  0.049533 -0.095392  0.134804  0.148821 -1.055648  0.522865  0.401585   \n",
       "207 -0.137949 -0.064979 -0.788619 -0.575067 -0.970839 -1.200244 -0.912514   \n",
       "\n",
       "           7         8         9   ...        51        52        53  \\\n",
       "0    0.297843  1.125272  0.021186  ... -1.115432 -0.597604  0.680897   \n",
       "1    2.510982  1.318325  0.588706  ... -0.522349 -0.256857 -0.843151   \n",
       "2    2.852370  3.232767  3.066105  ...  1.017585  0.836373 -0.197833   \n",
       "3   -0.084747 -1.000852 -0.610469  ... -0.137365 -1.009341  0.557326   \n",
       "4    1.317299  1.510531  1.772220  ... -1.073812 -0.753780 -0.060532   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "203  0.407323  0.463980  0.448504  ... -0.189390 -0.129077  1.230104   \n",
       "204 -0.388465 -0.635067  0.053253  ... -0.761663 -0.200066  0.351373   \n",
       "205 -0.200113 -0.442014  0.332912  ...  0.268428 -1.108725 -0.801960   \n",
       "206 -0.264859  0.139685  0.202404  ... -0.501539 -0.867363  0.227802   \n",
       "207  0.061226  0.053319  0.202404  ...  0.122759  0.311055 -0.856881   \n",
       "\n",
       "           54        55        56        57        58        59  60  \n",
       "0   -0.295646  1.481635  1.763784  0.069870  0.171678 -0.658947   0  \n",
       "1    0.015503  1.901046  1.070732 -0.472406 -0.444554 -0.419852   0  \n",
       "2    1.231812  2.827246  4.120162  1.309360  0.252761  0.257582   0  \n",
       "3   -0.111785 -0.161060 -0.488635 -0.549875 -0.639154  1.034640   0  \n",
       "4    0.241793 -1.174638 -0.107456 -0.487900  0.447361  0.576375   0  \n",
       "..        ...       ...       ...       ...       ...       ...  ..  \n",
       "203 -0.847228  0.328253 -0.228741  0.550172  1.841992  1.831621   1  \n",
       "204 -0.422934 -0.335815 -0.765856 -0.735798 -0.282388  0.038412   1  \n",
       "205 -0.437077  0.118548  1.070732  0.906526 -0.039138 -0.678871   1  \n",
       "206 -0.804798 -0.825128 -0.765856 -0.007598 -0.704020 -0.340154   1  \n",
       "207 -0.762369 -0.370766 -0.661898 -0.673823 -0.298604  0.994790   1  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_dfMinMax = sonar_data.copy()\n",
    "for x in range(60):\n",
    "    normalized_dfMinMax[x] = MinMaxScaler().fit_transform(np.array(normalized_dfMinMax[x]).reshape(-1,1))\n",
    "\n",
    "normalized_dfMinMax\n",
    "\n",
    "normalized_df = sonar_data.copy()\n",
    "for x in range(60):\n",
    "    normalized_df[x] = StandardScaler().fit_transform(np.array(normalized_df[x]).reshape(-1,1))\n",
    "\n",
    "normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb29279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.708035e-17</td>\n",
       "      <td>6.832142e-17</td>\n",
       "      <td>-1.195625e-16</td>\n",
       "      <td>1.622634e-16</td>\n",
       "      <td>-1.793437e-16</td>\n",
       "      <td>2.049643e-16</td>\n",
       "      <td>1.024821e-16</td>\n",
       "      <td>3.416071e-17</td>\n",
       "      <td>-3.757678e-16</td>\n",
       "      <td>3.416071e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024821e-16</td>\n",
       "      <td>3.416071e-17</td>\n",
       "      <td>-1.451830e-16</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>-2.391250e-16</td>\n",
       "      <td>3.416071e-17</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>1.345078e-16</td>\n",
       "      <td>7.686159e-17</td>\n",
       "      <td>0.533654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>1.002413e+00</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.206158e+00</td>\n",
       "      <td>-1.150725e+00</td>\n",
       "      <td>-1.104253e+00</td>\n",
       "      <td>-1.036115e+00</td>\n",
       "      <td>-1.236093e+00</td>\n",
       "      <td>-1.600493e+00</td>\n",
       "      <td>-1.921613e+00</td>\n",
       "      <td>-1.522110e+00</td>\n",
       "      <td>-1.443689e+00</td>\n",
       "      <td>-1.468833e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.313126e+00</td>\n",
       "      <td>-1.449472e+00</td>\n",
       "      <td>-1.364897e+00</td>\n",
       "      <td>-1.229092e+00</td>\n",
       "      <td>-1.366868e+00</td>\n",
       "      <td>-1.302971e+00</td>\n",
       "      <td>-1.185113e+00</td>\n",
       "      <td>-1.271603e+00</td>\n",
       "      <td>-1.176985e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.894939e-01</td>\n",
       "      <td>-6.686781e-01</td>\n",
       "      <td>-6.490624e-01</td>\n",
       "      <td>-6.359298e-01</td>\n",
       "      <td>-6.703975e-01</td>\n",
       "      <td>-6.367565e-01</td>\n",
       "      <td>-6.626732e-01</td>\n",
       "      <td>-6.400918e-01</td>\n",
       "      <td>-6.856590e-01</td>\n",
       "      <td>-7.232644e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.394049e-01</td>\n",
       "      <td>-7.999231e-01</td>\n",
       "      <td>-7.642025e-01</td>\n",
       "      <td>-7.270112e-01</td>\n",
       "      <td>-6.678488e-01</td>\n",
       "      <td>-7.138771e-01</td>\n",
       "      <td>-6.738235e-01</td>\n",
       "      <td>-6.918580e-01</td>\n",
       "      <td>-6.788714e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.774703e-01</td>\n",
       "      <td>-2.322506e-01</td>\n",
       "      <td>-2.486515e-01</td>\n",
       "      <td>-2.120457e-01</td>\n",
       "      <td>-2.292089e-01</td>\n",
       "      <td>-2.106432e-01</td>\n",
       "      <td>-2.400524e-01</td>\n",
       "      <td>-2.672134e-01</td>\n",
       "      <td>-2.180558e-01</td>\n",
       "      <td>-1.928459e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.102002e-01</td>\n",
       "      <td>-1.645716e-01</td>\n",
       "      <td>-2.252935e-01</td>\n",
       "      <td>-2.532164e-01</td>\n",
       "      <td>-2.396997e-01</td>\n",
       "      <td>-3.240352e-01</td>\n",
       "      <td>-3.329639e-01</td>\n",
       "      <td>-2.499546e-01</td>\n",
       "      <td>-2.405314e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.784345e-01</td>\n",
       "      <td>2.893335e-01</td>\n",
       "      <td>3.682681e-01</td>\n",
       "      <td>2.285353e-01</td>\n",
       "      <td>4.524231e-01</td>\n",
       "      <td>5.012417e-01</td>\n",
       "      <td>5.232608e-01</td>\n",
       "      <td>4.096773e-01</td>\n",
       "      <td>4.692723e-01</td>\n",
       "      <td>4.507410e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.438640e-01</td>\n",
       "      <td>5.950106e-01</td>\n",
       "      <td>4.886751e-01</td>\n",
       "      <td>3.973675e-01</td>\n",
       "      <td>4.112618e-01</td>\n",
       "      <td>4.513169e-01</td>\n",
       "      <td>3.719959e-01</td>\n",
       "      <td>3.865486e-01</td>\n",
       "      <td>4.020352e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.706053e+00</td>\n",
       "      <td>5.944643e+00</td>\n",
       "      <td>6.836142e+00</td>\n",
       "      <td>8.025419e+00</td>\n",
       "      <td>5.878863e+00</td>\n",
       "      <td>4.710224e+00</td>\n",
       "      <td>4.074573e+00</td>\n",
       "      <td>3.816498e+00</td>\n",
       "      <td>4.274237e+00</td>\n",
       "      <td>3.746234e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.980752e+00</td>\n",
       "      <td>4.016680e+00</td>\n",
       "      <td>3.330819e+00</td>\n",
       "      <td>5.008027e+00</td>\n",
       "      <td>5.448568e+00</td>\n",
       "      <td>4.795888e+00</td>\n",
       "      <td>5.585599e+00</td>\n",
       "      <td>4.615037e+00</td>\n",
       "      <td>7.450343e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02   \n",
       "mean   1.708035e-17  6.832142e-17 -1.195625e-16  1.622634e-16 -1.793437e-16   \n",
       "std    1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00   \n",
       "min   -1.206158e+00 -1.150725e+00 -1.104253e+00 -1.036115e+00 -1.236093e+00   \n",
       "25%   -6.894939e-01 -6.686781e-01 -6.490624e-01 -6.359298e-01 -6.703975e-01   \n",
       "50%   -2.774703e-01 -2.322506e-01 -2.486515e-01 -2.120457e-01 -2.292089e-01   \n",
       "75%    2.784345e-01  2.893335e-01  3.682681e-01  2.285353e-01  4.524231e-01   \n",
       "max    4.706053e+00  5.944643e+00  6.836142e+00  8.025419e+00  5.878863e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02   \n",
       "mean   2.049643e-16  1.024821e-16  3.416071e-17 -3.757678e-16  3.416071e-17   \n",
       "std    1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00   \n",
       "min   -1.600493e+00 -1.921613e+00 -1.522110e+00 -1.443689e+00 -1.468833e+00   \n",
       "25%   -6.367565e-01 -6.626732e-01 -6.400918e-01 -6.856590e-01 -7.232644e-01   \n",
       "50%   -2.106432e-01 -2.400524e-01 -2.672134e-01 -2.180558e-01 -1.928459e-01   \n",
       "75%    5.012417e-01  5.232608e-01  4.096773e-01  4.692723e-01  4.507410e-01   \n",
       "max    4.710224e+00  4.074573e+00  3.816498e+00  4.274237e+00  3.746234e+00   \n",
       "\n",
       "       ...            51            52            53            54  \\\n",
       "count  ...  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02   \n",
       "mean   ...  1.024821e-16  3.416071e-17 -1.451830e-16  2.775558e-17   \n",
       "std    ...  1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00   \n",
       "min    ... -1.313126e+00 -1.449472e+00 -1.364897e+00 -1.229092e+00   \n",
       "25%    ... -6.394049e-01 -7.999231e-01 -7.642025e-01 -7.270112e-01   \n",
       "50%    ... -2.102002e-01 -1.645716e-01 -2.252935e-01 -2.532164e-01   \n",
       "75%    ...  3.438640e-01  5.950106e-01  4.886751e-01  3.973675e-01   \n",
       "max    ...  5.980752e+00  4.016680e+00  3.330819e+00  5.008027e+00   \n",
       "\n",
       "                 55            56            57            58            59  \\\n",
       "count  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02  2.080000e+02   \n",
       "mean  -2.391250e-16  3.416071e-17 -1.110223e-16  1.345078e-16  7.686159e-17   \n",
       "std    1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00  1.002413e+00   \n",
       "min   -1.366868e+00 -1.302971e+00 -1.185113e+00 -1.271603e+00 -1.176985e+00   \n",
       "25%   -6.678488e-01 -7.138771e-01 -6.738235e-01 -6.918580e-01 -6.788714e-01   \n",
       "50%   -2.396997e-01 -3.240352e-01 -3.329639e-01 -2.499546e-01 -2.405314e-01   \n",
       "75%    4.112618e-01  4.513169e-01  3.719959e-01  3.865486e-01  4.020352e-01   \n",
       "max    5.448568e+00  4.795888e+00  5.585599e+00  4.615037e+00  7.450343e+00   \n",
       "\n",
       "               60  \n",
       "count  208.000000  \n",
       "mean     0.533654  \n",
       "std      0.500070  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280fd150",
   "metadata": {},
   "source": [
    "Train test val split\n",
    "80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f752c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalized_df.drop(columns=60, axis=1)\n",
    "y = normalized_df[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebe8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb690bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166, 60)\n",
      "1    91\n",
      "0    75\n",
      "Name: 60, dtype: int64\n",
      "******\n",
      "(21, 60)\n",
      "1    11\n",
      "0    10\n",
      "Name: 60, dtype: int64\n",
      "******\n",
      "(21, 60)\n",
      "0    12\n",
      "1     9\n",
      "Name: 60, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.value_counts())\n",
    "print('******')\n",
    "print(X_test.shape)\n",
    "print(y_test.value_counts())\n",
    "print('******')\n",
    "print(X_val.shape)\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc608bc5",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbd99f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 22:44:09.079692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1b105",
   "metadata": {},
   "source": [
    "Vytvorenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4021b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 22:44:12.183471: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#nothing\n",
    "tf_model1 = Sequential()\n",
    "tf_model1.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns)))\n",
    "tf_model1.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model1.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model1.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "#dropout\n",
    "tf_model2 = Sequential()\n",
    "tf_model2.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns)))\n",
    "tf_model2.add(Dropout(0.5))\n",
    "tf_model2.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model2.add(Dropout(0.5))\n",
    "tf_model2.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model2.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "#early stopping\n",
    "tf_model3 = Sequential()\n",
    "tf_model3.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns)))\n",
    "tf_model3.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model3.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model3.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "#regularization\n",
    "tf_model4 = Sequential()\n",
    "tf_model4.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns), kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.005)))\n",
    "tf_model4.add(Dense(16, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.005)))\n",
    "tf_model4.add(Dense(16, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.005)))\n",
    "tf_model4.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "#dropout + earlystop\n",
    "tf_model5 = Sequential()\n",
    "tf_model5.add(Dense(16, activation=tf.keras.activations.relu, input_dim=len(X_train.columns)))\n",
    "tf_model5.add(Dropout(0.5))\n",
    "tf_model5.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model5.add(Dropout(0.5))\n",
    "tf_model5.add(Dense(16, activation=tf.keras.activations.relu))\n",
    "tf_model5.add(Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a04d45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "tf_model1.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])\n",
    "tf_model2.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])\n",
    "tf_model3.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])\n",
    "tf_model4.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])\n",
    "tf_model5.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=Adam(), metrics=['accuracy', 'mse', precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a713898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(model, name, callbackArg):\n",
    "    \n",
    "    model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callbackArg\n",
    "    )\n",
    "\n",
    "    model.save('./'+ name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce86c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 0.6991 - accuracy: 0.5301 - mse: 0.2527 - precision: 0.5414 - recall: 0.9341 - val_loss: 0.7403 - val_accuracy: 0.4762 - val_mse: 0.2729 - val_precision: 0.4444 - val_recall: 0.8889\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.5904 - mse: 0.2325 - precision: 0.5793 - recall: 0.9231 - val_loss: 0.7027 - val_accuracy: 0.4762 - val_mse: 0.2551 - val_precision: 0.4444 - val_recall: 0.8889\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6807 - mse: 0.2181 - precision: 0.6484 - recall: 0.9121 - val_loss: 0.6838 - val_accuracy: 0.5238 - val_mse: 0.2462 - val_precision: 0.4706 - val_recall: 0.8889\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7349 - mse: 0.2066 - precision: 0.6942 - recall: 0.9231 - val_loss: 0.6678 - val_accuracy: 0.5714 - val_mse: 0.2387 - val_precision: 0.5000 - val_recall: 0.8889\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.7410 - mse: 0.1953 - precision: 0.7105 - recall: 0.8901 - val_loss: 0.6500 - val_accuracy: 0.6190 - val_mse: 0.2304 - val_precision: 0.5333 - val_recall: 0.8889\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7771 - mse: 0.1846 - precision: 0.7500 - recall: 0.8901 - val_loss: 0.6307 - val_accuracy: 0.7143 - val_mse: 0.2214 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8012 - mse: 0.1732 - precision: 0.7788 - recall: 0.8901 - val_loss: 0.6099 - val_accuracy: 0.7143 - val_mse: 0.2121 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.8133 - mse: 0.1617 - precision: 0.7941 - recall: 0.8901 - val_loss: 0.5872 - val_accuracy: 0.7143 - val_mse: 0.2027 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8072 - mse: 0.1493 - precision: 0.7980 - recall: 0.8681 - val_loss: 0.5687 - val_accuracy: 0.7143 - val_mse: 0.1957 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8193 - mse: 0.1379 - precision: 0.8144 - recall: 0.8681 - val_loss: 0.5605 - val_accuracy: 0.7143 - val_mse: 0.1928 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8494 - mse: 0.1260 - precision: 0.8438 - recall: 0.8901 - val_loss: 0.5462 - val_accuracy: 0.7619 - val_mse: 0.1883 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8434 - mse: 0.1146 - precision: 0.8351 - recall: 0.8901 - val_loss: 0.5432 - val_accuracy: 0.8095 - val_mse: 0.1871 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8554 - mse: 0.1052 - precision: 0.8526 - recall: 0.8901 - val_loss: 0.5265 - val_accuracy: 0.8095 - val_mse: 0.1821 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8795 - mse: 0.0955 - precision: 0.8817 - recall: 0.9011 - val_loss: 0.5108 - val_accuracy: 0.8095 - val_mse: 0.1777 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2950 - accuracy: 0.9096 - mse: 0.0861 - precision: 0.9043 - recall: 0.9341 - val_loss: 0.5143 - val_accuracy: 0.8095 - val_mse: 0.1784 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.9217 - mse: 0.0784 - precision: 0.8980 - recall: 0.9670 - val_loss: 0.5117 - val_accuracy: 0.8095 - val_mse: 0.1764 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9277 - mse: 0.0693 - precision: 0.9158 - recall: 0.9560 - val_loss: 0.4613 - val_accuracy: 0.8095 - val_mse: 0.1631 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9518 - mse: 0.0588 - precision: 0.9368 - recall: 0.9780 - val_loss: 0.4577 - val_accuracy: 0.8095 - val_mse: 0.1600 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1982 - accuracy: 0.9518 - mse: 0.0528 - precision: 0.9278 - recall: 0.9890 - val_loss: 0.4547 - val_accuracy: 0.8095 - val_mse: 0.1567 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9759 - mse: 0.0442 - precision: 0.9677 - recall: 0.9890 - val_loss: 0.4444 - val_accuracy: 0.8095 - val_mse: 0.1550 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9759 - mse: 0.0376 - precision: 0.9677 - recall: 0.9890 - val_loss: 0.4597 - val_accuracy: 0.8095 - val_mse: 0.1596 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9819 - mse: 0.0327 - precision: 0.9783 - recall: 0.9890 - val_loss: 0.4680 - val_accuracy: 0.8095 - val_mse: 0.1607 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1234 - accuracy: 0.9819 - mse: 0.0282 - precision: 0.9783 - recall: 0.9890 - val_loss: 0.4541 - val_accuracy: 0.8095 - val_mse: 0.1545 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9880 - mse: 0.0237 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.4575 - val_accuracy: 0.8095 - val_mse: 0.1549 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9880 - mse: 0.0207 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.4617 - val_accuracy: 0.8095 - val_mse: 0.1557 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9880 - mse: 0.0177 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.4627 - val_accuracy: 0.8095 - val_mse: 0.1570 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9880 - mse: 0.0151 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.4676 - val_accuracy: 0.8095 - val_mse: 0.1576 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9880 - mse: 0.0131 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.4784 - val_accuracy: 0.8095 - val_mse: 0.1608 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9940 - mse: 0.0106 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.4819 - val_accuracy: 0.8095 - val_mse: 0.1582 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9940 - mse: 0.0092 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.5023 - val_accuracy: 0.8095 - val_mse: 0.1622 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9880 - mse: 0.0081 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.5247 - val_accuracy: 0.8095 - val_mse: 0.1668 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 1.0000 - mse: 0.0060 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.8095 - val_mse: 0.1678 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 1.0000 - mse: 0.0053 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.8095 - val_mse: 0.1698 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 1.0000 - mse: 0.0044 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.8095 - val_mse: 0.1692 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 1.0000 - mse: 0.0036 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.8095 - val_mse: 0.1723 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000 - mse: 0.0028 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.8095 - val_mse: 0.1741 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000 - mse: 0.0025 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6025 - val_accuracy: 0.8095 - val_mse: 0.1754 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000 - mse: 0.0018 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6118 - val_accuracy: 0.8095 - val_mse: 0.1758 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000 - mse: 0.0016 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.8095 - val_mse: 0.1761 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000 - mse: 0.0014 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.8095 - val_mse: 0.1766 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000 - mse: 0.0012 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.8095 - val_mse: 0.1790 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - mse: 8.2815e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.8095 - val_mse: 0.1779 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000 - mse: 7.8304e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8095 - val_mse: 0.1789 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 1.0000 - mse: 6.4544e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6774 - val_accuracy: 0.8095 - val_mse: 0.1793 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000 - mse: 4.8458e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8095 - val_mse: 0.1821 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000 - mse: 4.8201e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8095 - val_mse: 0.1825 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000 - mse: 4.0130e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.8095 - val_mse: 0.1821 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - mse: 3.1590e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.8095 - val_mse: 0.1820 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000 - mse: 2.7062e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.8095 - val_mse: 0.1821 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000 - mse: 2.3956e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7427 - val_accuracy: 0.8095 - val_mse: 0.1820 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - mse: 2.0969e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7484 - val_accuracy: 0.8095 - val_mse: 0.1833 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - mse: 1.8536e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8095 - val_mse: 0.1833 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - mse: 1.5366e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8095 - val_mse: 0.1835 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - mse: 1.3630e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7743 - val_accuracy: 0.8095 - val_mse: 0.1837 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - mse: 1.1921e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.8095 - val_mse: 0.1836 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - mse: 1.0618e-04 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.8095 - val_mse: 0.1837 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - mse: 9.5700e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7937 - val_accuracy: 0.8095 - val_mse: 0.1841 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - mse: 8.4510e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8019 - val_accuracy: 0.8095 - val_mse: 0.1840 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - mse: 7.6818e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.8095 - val_mse: 0.1842 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - mse: 7.2652e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.8095 - val_mse: 0.1848 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - mse: 6.5794e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8266 - val_accuracy: 0.8095 - val_mse: 0.1852 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - mse: 5.7493e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8359 - val_accuracy: 0.8095 - val_mse: 0.1851 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - mse: 4.9481e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8408 - val_accuracy: 0.8095 - val_mse: 0.1852 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - mse: 4.5043e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8417 - val_accuracy: 0.8095 - val_mse: 0.1851 - val_precision: 0.7273 - val_recall: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - mse: 4.1067e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8493 - val_accuracy: 0.8095 - val_mse: 0.1852 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - mse: 3.8483e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8598 - val_accuracy: 0.8095 - val_mse: 0.1855 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - mse: 3.4087e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8672 - val_accuracy: 0.8095 - val_mse: 0.1857 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - mse: 3.1281e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8718 - val_accuracy: 0.8095 - val_mse: 0.1858 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - mse: 2.9227e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8753 - val_accuracy: 0.8095 - val_mse: 0.1863 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - mse: 2.6852e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.8095 - val_mse: 0.1864 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - mse: 2.4471e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8885 - val_accuracy: 0.8095 - val_mse: 0.1864 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - mse: 2.2323e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8951 - val_accuracy: 0.8095 - val_mse: 0.1865 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - mse: 2.0615e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.8095 - val_mse: 0.1865 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - mse: 1.8802e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9047 - val_accuracy: 0.8095 - val_mse: 0.1866 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - mse: 1.7766e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9104 - val_accuracy: 0.8095 - val_mse: 0.1866 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - mse: 1.6427e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9154 - val_accuracy: 0.8095 - val_mse: 0.1868 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - mse: 1.5312e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9230 - val_accuracy: 0.8095 - val_mse: 0.1869 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - mse: 1.4450e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.8095 - val_mse: 0.1871 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - mse: 1.3320e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9333 - val_accuracy: 0.8095 - val_mse: 0.1868 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - mse: 1.2334e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.8095 - val_mse: 0.1869 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - mse: 1.1499e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.8095 - val_mse: 0.1870 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - mse: 1.0650e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9497 - val_accuracy: 0.8095 - val_mse: 0.1872 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - mse: 1.0051e-05 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.8095 - val_mse: 0.1874 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - mse: 9.2336e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.8095 - val_mse: 0.1874 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - mse: 8.5871e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.8095 - val_mse: 0.1875 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - mse: 8.1023e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.8095 - val_mse: 0.1877 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - mse: 7.5227e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9697 - val_accuracy: 0.8095 - val_mse: 0.1877 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - mse: 7.1519e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.8095 - val_mse: 0.1878 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - mse: 6.5845e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9821 - val_accuracy: 0.8095 - val_mse: 0.1876 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - mse: 6.3534e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.8095 - val_mse: 0.1876 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - mse: 5.8439e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.8095 - val_mse: 0.1878 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - mse: 5.5053e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9939 - val_accuracy: 0.8095 - val_mse: 0.1879 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - mse: 5.1511e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.8095 - val_mse: 0.1880 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - mse: 4.8427e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.8095 - val_mse: 0.1881 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - mse: 4.5832e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0053 - val_accuracy: 0.8095 - val_mse: 0.1882 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - mse: 4.3444e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.8095 - val_mse: 0.1882 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - mse: 4.1269e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.8095 - val_mse: 0.1883 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.8176e-04 - accuracy: 1.0000 - mse: 3.8860e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.8095 - val_mse: 0.1884 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.5720e-04 - accuracy: 1.0000 - mse: 3.6898e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0216 - val_accuracy: 0.8095 - val_mse: 0.1884 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3285e-04 - accuracy: 1.0000 - mse: 3.5008e-06 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0255 - val_accuracy: 0.8095 - val_mse: 0.1884 - val_precision: 0.7273 - val_recall: 0.8889\n",
      "INFO:tensorflow:Assets written to: ./model1/assets\n"
     ]
    }
   ],
   "source": [
    "fitModel(tf_model1, 'model1', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1723e113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.8240 - accuracy: 0.5120 - mse: 0.2929 - precision: 0.5773 - recall: 0.5600 - val_loss: 0.7736 - val_accuracy: 0.4286 - val_mse: 0.2872 - val_precision: 0.4000 - val_recall: 0.6667\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.5663 - mse: 0.2573 - precision: 0.5979 - recall: 0.6374 - val_loss: 0.7591 - val_accuracy: 0.4286 - val_mse: 0.2806 - val_precision: 0.4000 - val_recall: 0.6667\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8258 - accuracy: 0.5482 - mse: 0.2874 - precision: 0.5833 - recall: 0.6154 - val_loss: 0.7435 - val_accuracy: 0.4762 - val_mse: 0.2736 - val_precision: 0.4286 - val_recall: 0.6667\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7220 - accuracy: 0.5843 - mse: 0.2569 - precision: 0.6100 - recall: 0.6703 - val_loss: 0.7361 - val_accuracy: 0.4762 - val_mse: 0.2702 - val_precision: 0.4286 - val_recall: 0.6667\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.5663 - mse: 0.2606 - precision: 0.6000 - recall: 0.6264 - val_loss: 0.7272 - val_accuracy: 0.4762 - val_mse: 0.2661 - val_precision: 0.4286 - val_recall: 0.6667\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5482 - mse: 0.2504 - precision: 0.5784 - recall: 0.6484 - val_loss: 0.7185 - val_accuracy: 0.5238 - val_mse: 0.2620 - val_precision: 0.4615 - val_recall: 0.6667\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7459 - accuracy: 0.5542 - mse: 0.2651 - precision: 0.5810 - recall: 0.6703 - val_loss: 0.7114 - val_accuracy: 0.5238 - val_mse: 0.2587 - val_precision: 0.4615 - val_recall: 0.6667\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7581 - accuracy: 0.5542 - mse: 0.2636 - precision: 0.5842 - recall: 0.6484 - val_loss: 0.7085 - val_accuracy: 0.4762 - val_mse: 0.2575 - val_precision: 0.4286 - val_recall: 0.6667\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7279 - accuracy: 0.5060 - mse: 0.2606 - precision: 0.5455 - recall: 0.5934 - val_loss: 0.6949 - val_accuracy: 0.4762 - val_mse: 0.2511 - val_precision: 0.4286 - val_recall: 0.6667\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5723 - mse: 0.2412 - precision: 0.5833 - recall: 0.7692 - val_loss: 0.6929 - val_accuracy: 0.5238 - val_mse: 0.2502 - val_precision: 0.4667 - val_recall: 0.7778\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.5361 - mse: 0.2611 - precision: 0.5636 - recall: 0.6813 - val_loss: 0.6829 - val_accuracy: 0.5238 - val_mse: 0.2453 - val_precision: 0.4667 - val_recall: 0.7778\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.5663 - mse: 0.2530 - precision: 0.5922 - recall: 0.6703 - val_loss: 0.6770 - val_accuracy: 0.5714 - val_mse: 0.2423 - val_precision: 0.5000 - val_recall: 0.7778\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.5723 - mse: 0.2496 - precision: 0.5943 - recall: 0.6923 - val_loss: 0.6735 - val_accuracy: 0.5714 - val_mse: 0.2406 - val_precision: 0.5000 - val_recall: 0.7778\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6145 - mse: 0.2337 - precision: 0.6239 - recall: 0.7473 - val_loss: 0.6682 - val_accuracy: 0.5714 - val_mse: 0.2380 - val_precision: 0.5000 - val_recall: 0.7778\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5542 - mse: 0.2468 - precision: 0.5780 - recall: 0.6923 - val_loss: 0.6643 - val_accuracy: 0.5714 - val_mse: 0.2361 - val_precision: 0.5000 - val_recall: 0.7778\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6024 - mse: 0.2295 - precision: 0.6263 - recall: 0.6813 - val_loss: 0.6625 - val_accuracy: 0.6190 - val_mse: 0.2352 - val_precision: 0.5333 - val_recall: 0.8889\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6265 - mse: 0.2307 - precision: 0.6261 - recall: 0.7912 - val_loss: 0.6639 - val_accuracy: 0.6190 - val_mse: 0.2359 - val_precision: 0.5333 - val_recall: 0.8889\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.6446 - mse: 0.2200 - precision: 0.6481 - recall: 0.7692 - val_loss: 0.6640 - val_accuracy: 0.6190 - val_mse: 0.2360 - val_precision: 0.5333 - val_recall: 0.8889\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6566 - mse: 0.2116 - precision: 0.6491 - recall: 0.8132 - val_loss: 0.6624 - val_accuracy: 0.6190 - val_mse: 0.2353 - val_precision: 0.5333 - val_recall: 0.8889\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.6084 - mse: 0.2357 - precision: 0.6121 - recall: 0.7802 - val_loss: 0.6585 - val_accuracy: 0.6190 - val_mse: 0.2334 - val_precision: 0.5333 - val_recall: 0.8889\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6265 - mse: 0.2101 - precision: 0.6330 - recall: 0.7582 - val_loss: 0.6500 - val_accuracy: 0.6190 - val_mse: 0.2294 - val_precision: 0.5333 - val_recall: 0.8889\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6386 - mse: 0.2303 - precision: 0.6535 - recall: 0.7253 - val_loss: 0.6449 - val_accuracy: 0.6190 - val_mse: 0.2270 - val_precision: 0.5333 - val_recall: 0.8889\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6386 - mse: 0.2247 - precision: 0.6422 - recall: 0.7692 - val_loss: 0.6390 - val_accuracy: 0.6667 - val_mse: 0.2242 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.6084 - mse: 0.2090 - precision: 0.6182 - recall: 0.7473 - val_loss: 0.6322 - val_accuracy: 0.6667 - val_mse: 0.2210 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6024 - mse: 0.2297 - precision: 0.6068 - recall: 0.7802 - val_loss: 0.6260 - val_accuracy: 0.6667 - val_mse: 0.2181 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6867 - mse: 0.1981 - precision: 0.6822 - recall: 0.8022 - val_loss: 0.6196 - val_accuracy: 0.6667 - val_mse: 0.2152 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.6988 - mse: 0.2057 - precision: 0.6881 - recall: 0.8242 - val_loss: 0.6139 - val_accuracy: 0.6667 - val_mse: 0.2127 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.6928 - mse: 0.2069 - precision: 0.6923 - recall: 0.7912 - val_loss: 0.6084 - val_accuracy: 0.6667 - val_mse: 0.2104 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6687 - mse: 0.2032 - precision: 0.6579 - recall: 0.8242 - val_loss: 0.6060 - val_accuracy: 0.6667 - val_mse: 0.2093 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6566 - mse: 0.2135 - precision: 0.6700 - recall: 0.7363 - val_loss: 0.6025 - val_accuracy: 0.6667 - val_mse: 0.2078 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.6928 - mse: 0.1901 - precision: 0.6818 - recall: 0.8242 - val_loss: 0.5955 - val_accuracy: 0.6667 - val_mse: 0.2049 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.6807 - mse: 0.1945 - precision: 0.6792 - recall: 0.7912 - val_loss: 0.5853 - val_accuracy: 0.6667 - val_mse: 0.2007 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7108 - mse: 0.1838 - precision: 0.7216 - recall: 0.7692 - val_loss: 0.5810 - val_accuracy: 0.6667 - val_mse: 0.1991 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.6988 - mse: 0.1936 - precision: 0.6814 - recall: 0.8462 - val_loss: 0.5758 - val_accuracy: 0.6667 - val_mse: 0.1972 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7530 - mse: 0.1759 - precision: 0.7404 - recall: 0.8462 - val_loss: 0.5664 - val_accuracy: 0.6667 - val_mse: 0.1938 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.6747 - mse: 0.1848 - precision: 0.6667 - recall: 0.8132 - val_loss: 0.5602 - val_accuracy: 0.6667 - val_mse: 0.1918 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7229 - mse: 0.1726 - precision: 0.7228 - recall: 0.8022 - val_loss: 0.5586 - val_accuracy: 0.6667 - val_mse: 0.1916 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.6928 - mse: 0.1673 - precision: 0.6852 - recall: 0.8132 - val_loss: 0.5567 - val_accuracy: 0.6667 - val_mse: 0.1911 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7771 - mse: 0.1702 - precision: 0.7500 - recall: 0.8901 - val_loss: 0.5530 - val_accuracy: 0.6667 - val_mse: 0.1898 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7108 - mse: 0.1838 - precision: 0.6937 - recall: 0.8462 - val_loss: 0.5518 - val_accuracy: 0.6667 - val_mse: 0.1895 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7108 - mse: 0.1777 - precision: 0.6870 - recall: 0.8681 - val_loss: 0.5493 - val_accuracy: 0.6667 - val_mse: 0.1887 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7470 - mse: 0.1589 - precision: 0.7094 - recall: 0.9121 - val_loss: 0.5440 - val_accuracy: 0.6667 - val_mse: 0.1871 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7229 - mse: 0.1715 - precision: 0.7064 - recall: 0.8462 - val_loss: 0.5382 - val_accuracy: 0.6667 - val_mse: 0.1853 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7349 - mse: 0.1639 - precision: 0.7117 - recall: 0.8681 - val_loss: 0.5338 - val_accuracy: 0.6667 - val_mse: 0.1838 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.7530 - mse: 0.1319 - precision: 0.7315 - recall: 0.8681 - val_loss: 0.5297 - val_accuracy: 0.6667 - val_mse: 0.1823 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7892 - mse: 0.1386 - precision: 0.7593 - recall: 0.9011 - val_loss: 0.5251 - val_accuracy: 0.6667 - val_mse: 0.1808 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7289 - mse: 0.1630 - precision: 0.7170 - recall: 0.8352 - val_loss: 0.5196 - val_accuracy: 0.6667 - val_mse: 0.1794 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7651 - mse: 0.1557 - precision: 0.7453 - recall: 0.8681 - val_loss: 0.5130 - val_accuracy: 0.6667 - val_mse: 0.1776 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7651 - mse: 0.1495 - precision: 0.7500 - recall: 0.8571 - val_loss: 0.5096 - val_accuracy: 0.6190 - val_mse: 0.1770 - val_precision: 0.5385 - val_recall: 0.7778\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7831 - mse: 0.1506 - precision: 0.7523 - recall: 0.9011 - val_loss: 0.5052 - val_accuracy: 0.6190 - val_mse: 0.1761 - val_precision: 0.5385 - val_recall: 0.7778\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7530 - mse: 0.1548 - precision: 0.7232 - recall: 0.8901 - val_loss: 0.5001 - val_accuracy: 0.6190 - val_mse: 0.1748 - val_precision: 0.5385 - val_recall: 0.7778\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7229 - mse: 0.1694 - precision: 0.6991 - recall: 0.8681 - val_loss: 0.4952 - val_accuracy: 0.6667 - val_mse: 0.1731 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7892 - mse: 0.1415 - precision: 0.7500 - recall: 0.9231 - val_loss: 0.4874 - val_accuracy: 0.6667 - val_mse: 0.1698 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.7651 - mse: 0.1316 - precision: 0.7600 - recall: 0.8352 - val_loss: 0.4845 - val_accuracy: 0.6667 - val_mse: 0.1690 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7651 - mse: 0.1435 - precision: 0.7500 - recall: 0.8571 - val_loss: 0.4859 - val_accuracy: 0.6667 - val_mse: 0.1701 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8313 - mse: 0.1243 - precision: 0.7944 - recall: 0.9341 - val_loss: 0.4804 - val_accuracy: 0.6667 - val_mse: 0.1680 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8193 - mse: 0.1367 - precision: 0.7961 - recall: 0.9011 - val_loss: 0.4820 - val_accuracy: 0.6667 - val_mse: 0.1688 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7470 - mse: 0.1449 - precision: 0.7290 - recall: 0.8571 - val_loss: 0.4884 - val_accuracy: 0.6667 - val_mse: 0.1719 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7831 - mse: 0.1410 - precision: 0.7670 - recall: 0.8681 - val_loss: 0.4870 - val_accuracy: 0.7143 - val_mse: 0.1720 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.7952 - mse: 0.1283 - precision: 0.7767 - recall: 0.8791 - val_loss: 0.4882 - val_accuracy: 0.7143 - val_mse: 0.1732 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7711 - mse: 0.1416 - precision: 0.7624 - recall: 0.8462 - val_loss: 0.4801 - val_accuracy: 0.7143 - val_mse: 0.1702 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7831 - mse: 0.1433 - precision: 0.7723 - recall: 0.8571 - val_loss: 0.4698 - val_accuracy: 0.7143 - val_mse: 0.1661 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.7892 - mse: 0.1267 - precision: 0.7642 - recall: 0.8901 - val_loss: 0.4671 - val_accuracy: 0.7143 - val_mse: 0.1654 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8133 - mse: 0.1184 - precision: 0.8409 - recall: 0.8132 - val_loss: 0.4674 - val_accuracy: 0.7143 - val_mse: 0.1659 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.7892 - mse: 0.1332 - precision: 0.7800 - recall: 0.8571 - val_loss: 0.4604 - val_accuracy: 0.7143 - val_mse: 0.1634 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8193 - mse: 0.1250 - precision: 0.7961 - recall: 0.9011 - val_loss: 0.4558 - val_accuracy: 0.7143 - val_mse: 0.1621 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8072 - mse: 0.1114 - precision: 0.7980 - recall: 0.8681 - val_loss: 0.4576 - val_accuracy: 0.7143 - val_mse: 0.1636 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8012 - mse: 0.1098 - precision: 0.7843 - recall: 0.8791 - val_loss: 0.4568 - val_accuracy: 0.7143 - val_mse: 0.1640 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.7892 - mse: 0.1294 - precision: 0.7642 - recall: 0.8901 - val_loss: 0.4570 - val_accuracy: 0.7619 - val_mse: 0.1643 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.7771 - mse: 0.1307 - precision: 0.7812 - recall: 0.8242 - val_loss: 0.4566 - val_accuracy: 0.7619 - val_mse: 0.1636 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.7952 - mse: 0.1270 - precision: 0.8000 - recall: 0.8352 - val_loss: 0.4583 - val_accuracy: 0.7619 - val_mse: 0.1639 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8072 - mse: 0.1203 - precision: 0.7980 - recall: 0.8681 - val_loss: 0.4607 - val_accuracy: 0.7619 - val_mse: 0.1648 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8313 - mse: 0.1083 - precision: 0.8058 - recall: 0.9121 - val_loss: 0.4511 - val_accuracy: 0.7619 - val_mse: 0.1613 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8193 - mse: 0.1099 - precision: 0.8280 - recall: 0.8462 - val_loss: 0.4480 - val_accuracy: 0.7143 - val_mse: 0.1602 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8133 - mse: 0.1112 - precision: 0.8061 - recall: 0.8681 - val_loss: 0.4474 - val_accuracy: 0.7143 - val_mse: 0.1597 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8072 - mse: 0.1188 - precision: 0.8041 - recall: 0.8571 - val_loss: 0.4522 - val_accuracy: 0.7143 - val_mse: 0.1610 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8494 - mse: 0.1170 - precision: 0.8587 - recall: 0.8681 - val_loss: 0.4542 - val_accuracy: 0.7143 - val_mse: 0.1612 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.7771 - mse: 0.1181 - precision: 0.7812 - recall: 0.8242 - val_loss: 0.4423 - val_accuracy: 0.7143 - val_mse: 0.1573 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8253 - mse: 0.1317 - precision: 0.8523 - recall: 0.8242 - val_loss: 0.4394 - val_accuracy: 0.7143 - val_mse: 0.1552 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.8434 - mse: 0.0969 - precision: 0.8351 - recall: 0.8901 - val_loss: 0.4444 - val_accuracy: 0.7143 - val_mse: 0.1557 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8313 - mse: 0.1143 - precision: 0.8539 - recall: 0.8352 - val_loss: 0.4496 - val_accuracy: 0.7143 - val_mse: 0.1572 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8494 - mse: 0.1087 - precision: 0.8929 - recall: 0.8242 - val_loss: 0.4557 - val_accuracy: 0.7143 - val_mse: 0.1585 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8795 - mse: 0.0882 - precision: 0.8901 - recall: 0.8901 - val_loss: 0.4605 - val_accuracy: 0.7143 - val_mse: 0.1587 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8855 - mse: 0.0837 - precision: 0.8913 - recall: 0.9011 - val_loss: 0.4577 - val_accuracy: 0.7143 - val_mse: 0.1571 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8494 - mse: 0.1051 - precision: 0.8587 - recall: 0.8681 - val_loss: 0.4555 - val_accuracy: 0.7619 - val_mse: 0.1558 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8795 - mse: 0.0907 - precision: 0.8586 - recall: 0.9341 - val_loss: 0.4540 - val_accuracy: 0.7619 - val_mse: 0.1558 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8133 - mse: 0.1125 - precision: 0.8061 - recall: 0.8681 - val_loss: 0.4557 - val_accuracy: 0.7143 - val_mse: 0.1556 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8614 - mse: 0.1063 - precision: 0.8469 - recall: 0.9121 - val_loss: 0.4537 - val_accuracy: 0.7143 - val_mse: 0.1547 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8675 - mse: 0.0975 - precision: 0.9059 - recall: 0.8462 - val_loss: 0.4563 - val_accuracy: 0.7143 - val_mse: 0.1549 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8434 - mse: 0.0972 - precision: 0.8283 - recall: 0.9011 - val_loss: 0.4543 - val_accuracy: 0.7143 - val_mse: 0.1536 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.8554 - mse: 0.0971 - precision: 0.8851 - recall: 0.8462 - val_loss: 0.4617 - val_accuracy: 0.7143 - val_mse: 0.1548 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.8855 - mse: 0.0951 - precision: 0.8913 - recall: 0.9011 - val_loss: 0.4689 - val_accuracy: 0.7143 - val_mse: 0.1555 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8614 - mse: 0.0884 - precision: 0.8864 - recall: 0.8571 - val_loss: 0.4705 - val_accuracy: 0.7143 - val_mse: 0.1562 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8976 - mse: 0.0921 - precision: 0.8700 - recall: 0.9560 - val_loss: 0.4744 - val_accuracy: 0.7143 - val_mse: 0.1583 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.9157 - mse: 0.0868 - precision: 0.9140 - recall: 0.9341 - val_loss: 0.4751 - val_accuracy: 0.7619 - val_mse: 0.1585 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.8675 - mse: 0.0822 - precision: 0.8632 - recall: 0.9011 - val_loss: 0.4789 - val_accuracy: 0.7619 - val_mse: 0.1579 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8434 - mse: 0.0956 - precision: 0.8736 - recall: 0.8352 - val_loss: 0.4792 - val_accuracy: 0.7619 - val_mse: 0.1572 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8193 - mse: 0.1033 - precision: 0.8506 - recall: 0.8132 - val_loss: 0.4838 - val_accuracy: 0.7619 - val_mse: 0.1577 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8614 - mse: 0.0973 - precision: 0.9048 - recall: 0.8352 - val_loss: 0.4822 - val_accuracy: 0.7619 - val_mse: 0.1577 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8434 - mse: 0.0918 - precision: 0.8916 - recall: 0.8132 - val_loss: 0.4842 - val_accuracy: 0.7619 - val_mse: 0.1586 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "INFO:tensorflow:Assets written to: ./model2/assets\n"
     ]
    }
   ],
   "source": [
    "fitModel(tf_model2, 'model2', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b0e13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6999 - accuracy: 0.5482 - mse: 0.2521 - precision: 0.5575 - recall: 0.9700 - val_loss: 0.7369 - val_accuracy: 0.4286 - val_mse: 0.2707 - val_precision: 0.4286 - val_recall: 1.0000\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.5542 - mse: 0.2320 - precision: 0.5541 - recall: 0.9560 - val_loss: 0.6934 - val_accuracy: 0.5238 - val_mse: 0.2494 - val_precision: 0.4737 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.6325 - mse: 0.2144 - precision: 0.6056 - recall: 0.9451 - val_loss: 0.6716 - val_accuracy: 0.7143 - val_mse: 0.2380 - val_precision: 0.6000 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7048 - mse: 0.2005 - precision: 0.6694 - recall: 0.9121 - val_loss: 0.6460 - val_accuracy: 0.7143 - val_mse: 0.2254 - val_precision: 0.6000 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7831 - mse: 0.1879 - precision: 0.7477 - recall: 0.9121 - val_loss: 0.6294 - val_accuracy: 0.7143 - val_mse: 0.2171 - val_precision: 0.6000 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.8133 - mse: 0.1761 - precision: 0.7830 - recall: 0.9121 - val_loss: 0.6113 - val_accuracy: 0.7619 - val_mse: 0.2087 - val_precision: 0.6429 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8373 - mse: 0.1638 - precision: 0.8137 - recall: 0.9121 - val_loss: 0.5975 - val_accuracy: 0.8095 - val_mse: 0.2021 - val_precision: 0.6923 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.8554 - mse: 0.1519 - precision: 0.8454 - recall: 0.9011 - val_loss: 0.5748 - val_accuracy: 0.7143 - val_mse: 0.1921 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8554 - mse: 0.1383 - precision: 0.8681 - recall: 0.8681 - val_loss: 0.5535 - val_accuracy: 0.7619 - val_mse: 0.1831 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8855 - mse: 0.1274 - precision: 0.9091 - recall: 0.8791 - val_loss: 0.5235 - val_accuracy: 0.7619 - val_mse: 0.1725 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8916 - mse: 0.1148 - precision: 0.9195 - recall: 0.8791 - val_loss: 0.5040 - val_accuracy: 0.7619 - val_mse: 0.1659 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8916 - mse: 0.1038 - precision: 0.9195 - recall: 0.8791 - val_loss: 0.4912 - val_accuracy: 0.7143 - val_mse: 0.1621 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8976 - mse: 0.0942 - precision: 0.9205 - recall: 0.8901 - val_loss: 0.4776 - val_accuracy: 0.7619 - val_mse: 0.1569 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.9036 - mse: 0.0850 - precision: 0.9310 - recall: 0.8901 - val_loss: 0.4831 - val_accuracy: 0.7619 - val_mse: 0.1569 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.9036 - mse: 0.0758 - precision: 0.9310 - recall: 0.8901 - val_loss: 0.4609 - val_accuracy: 0.7619 - val_mse: 0.1510 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9217 - mse: 0.0663 - precision: 0.9643 - recall: 0.8901 - val_loss: 0.4648 - val_accuracy: 0.7619 - val_mse: 0.1519 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9337 - mse: 0.0580 - precision: 0.9651 - recall: 0.9121 - val_loss: 0.4475 - val_accuracy: 0.7619 - val_mse: 0.1478 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9398 - mse: 0.0504 - precision: 0.9765 - recall: 0.9121 - val_loss: 0.4649 - val_accuracy: 0.7619 - val_mse: 0.1518 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1782 - accuracy: 0.9518 - mse: 0.0445 - precision: 0.9770 - recall: 0.9341 - val_loss: 0.4806 - val_accuracy: 0.7619 - val_mse: 0.1539 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9578 - mse: 0.0388 - precision: 0.9884 - recall: 0.9341 - val_loss: 0.4818 - val_accuracy: 0.7619 - val_mse: 0.1525 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9578 - mse: 0.0341 - precision: 0.9884 - recall: 0.9341 - val_loss: 0.5057 - val_accuracy: 0.7619 - val_mse: 0.1570 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9699 - mse: 0.0294 - precision: 0.9886 - recall: 0.9560 - val_loss: 0.5222 - val_accuracy: 0.7143 - val_mse: 0.1601 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9699 - mse: 0.0253 - precision: 0.9886 - recall: 0.9560 - val_loss: 0.5421 - val_accuracy: 0.7143 - val_mse: 0.1624 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9699 - mse: 0.0216 - precision: 0.9886 - recall: 0.9560 - val_loss: 0.5535 - val_accuracy: 0.7619 - val_mse: 0.1598 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9819 - mse: 0.0180 - precision: 1.0000 - recall: 0.9670 - val_loss: 0.5788 - val_accuracy: 0.7143 - val_mse: 0.1630 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9880 - mse: 0.0150 - precision: 1.0000 - recall: 0.9780 - val_loss: 0.5971 - val_accuracy: 0.7143 - val_mse: 0.1631 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9940 - mse: 0.0119 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.6222 - val_accuracy: 0.7143 - val_mse: 0.1658 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "INFO:tensorflow:Assets written to: ./model3/assets\n"
     ]
    }
   ],
   "source": [
    "fitModel(tf_model3, 'model3', [earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad287c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 16ms/step - loss: 2.2075 - accuracy: 0.5120 - mse: 0.2532 - precision: 0.5455 - recall: 0.7800 - val_loss: 2.1692 - val_accuracy: 0.4286 - val_mse: 0.2505 - val_precision: 0.4211 - val_recall: 0.8889\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.1232 - accuracy: 0.5843 - mse: 0.2395 - precision: 0.5775 - recall: 0.9011 - val_loss: 2.1095 - val_accuracy: 0.4762 - val_mse: 0.2482 - val_precision: 0.4500 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0489 - accuracy: 0.6024 - mse: 0.2299 - precision: 0.5874 - recall: 0.9231 - val_loss: 2.0478 - val_accuracy: 0.5238 - val_mse: 0.2442 - val_precision: 0.4737 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9803 - accuracy: 0.6145 - mse: 0.2227 - precision: 0.5957 - recall: 0.9231 - val_loss: 1.9907 - val_accuracy: 0.6190 - val_mse: 0.2419 - val_precision: 0.5294 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9123 - accuracy: 0.6386 - mse: 0.2154 - precision: 0.6131 - recall: 0.9231 - val_loss: 1.9331 - val_accuracy: 0.6190 - val_mse: 0.2388 - val_precision: 0.5294 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8453 - accuracy: 0.6627 - mse: 0.2081 - precision: 0.6336 - recall: 0.9121 - val_loss: 1.8791 - val_accuracy: 0.6190 - val_mse: 0.2367 - val_precision: 0.5294 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7793 - accuracy: 0.6867 - mse: 0.2005 - precision: 0.6512 - recall: 0.9231 - val_loss: 1.8266 - val_accuracy: 0.5714 - val_mse: 0.2337 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7148 - accuracy: 0.7289 - mse: 0.1930 - precision: 0.6825 - recall: 0.9451 - val_loss: 1.7746 - val_accuracy: 0.6667 - val_mse: 0.2297 - val_precision: 0.5625 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6528 - accuracy: 0.7590 - mse: 0.1857 - precision: 0.7143 - recall: 0.9341 - val_loss: 1.7270 - val_accuracy: 0.6667 - val_mse: 0.2264 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5900 - accuracy: 0.8012 - mse: 0.1770 - precision: 0.7589 - recall: 0.9341 - val_loss: 1.6710 - val_accuracy: 0.6667 - val_mse: 0.2195 - val_precision: 0.5714 - val_recall: 0.8889\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5285 - accuracy: 0.8193 - mse: 0.1678 - precision: 0.7850 - recall: 0.9231 - val_loss: 1.6201 - val_accuracy: 0.7143 - val_mse: 0.2137 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4715 - accuracy: 0.8313 - mse: 0.1597 - precision: 0.8058 - recall: 0.9121 - val_loss: 1.5622 - val_accuracy: 0.7143 - val_mse: 0.2046 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4113 - accuracy: 0.8614 - mse: 0.1495 - precision: 0.8469 - recall: 0.9121 - val_loss: 1.5197 - val_accuracy: 0.7143 - val_mse: 0.2004 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3530 - accuracy: 0.8614 - mse: 0.1395 - precision: 0.8469 - recall: 0.9121 - val_loss: 1.4711 - val_accuracy: 0.8095 - val_mse: 0.1937 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2953 - accuracy: 0.8554 - mse: 0.1291 - precision: 0.8454 - recall: 0.9011 - val_loss: 1.4399 - val_accuracy: 0.8095 - val_mse: 0.1893 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2383 - accuracy: 0.8735 - mse: 0.1185 - precision: 0.8571 - recall: 0.9231 - val_loss: 1.3921 - val_accuracy: 0.8095 - val_mse: 0.1801 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1816 - accuracy: 0.8855 - mse: 0.1070 - precision: 0.8750 - recall: 0.9231 - val_loss: 1.3417 - val_accuracy: 0.8095 - val_mse: 0.1706 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1301 - accuracy: 0.9036 - mse: 0.0974 - precision: 0.8947 - recall: 0.9341 - val_loss: 1.3023 - val_accuracy: 0.8571 - val_mse: 0.1624 - val_precision: 0.8750 - val_recall: 0.7778\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0761 - accuracy: 0.9096 - mse: 0.0862 - precision: 0.9130 - recall: 0.9231 - val_loss: 1.2659 - val_accuracy: 0.8571 - val_mse: 0.1546 - val_precision: 0.8750 - val_recall: 0.7778\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0274 - accuracy: 0.9277 - mse: 0.0770 - precision: 0.9341 - recall: 0.9341 - val_loss: 1.2389 - val_accuracy: 0.8571 - val_mse: 0.1485 - val_precision: 0.8750 - val_recall: 0.7778\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9801 - accuracy: 0.9398 - mse: 0.0687 - precision: 0.9451 - recall: 0.9451 - val_loss: 1.2122 - val_accuracy: 0.8571 - val_mse: 0.1452 - val_precision: 0.8750 - val_recall: 0.7778\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9354 - accuracy: 0.9458 - mse: 0.0606 - precision: 0.9457 - recall: 0.9560 - val_loss: 1.1933 - val_accuracy: 0.8571 - val_mse: 0.1427 - val_precision: 0.8750 - val_recall: 0.7778\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8955 - accuracy: 0.9639 - mse: 0.0540 - precision: 0.9775 - recall: 0.9560 - val_loss: 1.1756 - val_accuracy: 0.8571 - val_mse: 0.1403 - val_precision: 0.8750 - val_recall: 0.7778\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8571 - accuracy: 0.9578 - mse: 0.0483 - precision: 0.9667 - recall: 0.9560 - val_loss: 1.1551 - val_accuracy: 0.8095 - val_mse: 0.1384 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8230 - accuracy: 0.9639 - mse: 0.0441 - precision: 0.9670 - recall: 0.9670 - val_loss: 1.1451 - val_accuracy: 0.8095 - val_mse: 0.1389 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7904 - accuracy: 0.9699 - mse: 0.0398 - precision: 0.9778 - recall: 0.9670 - val_loss: 1.1426 - val_accuracy: 0.8095 - val_mse: 0.1380 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.9639 - mse: 0.0373 - precision: 0.9775 - recall: 0.9560 - val_loss: 1.1283 - val_accuracy: 0.8095 - val_mse: 0.1357 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.9639 - mse: 0.0335 - precision: 0.9670 - recall: 0.9670 - val_loss: 1.1056 - val_accuracy: 0.8095 - val_mse: 0.1366 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.9639 - mse: 0.0307 - precision: 0.9670 - recall: 0.9670 - val_loss: 1.1085 - val_accuracy: 0.8095 - val_mse: 0.1371 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.9699 - mse: 0.0284 - precision: 0.9778 - recall: 0.9670 - val_loss: 1.0818 - val_accuracy: 0.8095 - val_mse: 0.1367 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.9759 - mse: 0.0263 - precision: 0.9888 - recall: 0.9670 - val_loss: 1.0761 - val_accuracy: 0.8095 - val_mse: 0.1376 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.9819 - mse: 0.0247 - precision: 1.0000 - recall: 0.9670 - val_loss: 1.0579 - val_accuracy: 0.8095 - val_mse: 0.1372 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.9819 - mse: 0.0231 - precision: 1.0000 - recall: 0.9670 - val_loss: 1.0422 - val_accuracy: 0.8095 - val_mse: 0.1364 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.9819 - mse: 0.0213 - precision: 1.0000 - recall: 0.9670 - val_loss: 1.0192 - val_accuracy: 0.8095 - val_mse: 0.1362 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.9819 - mse: 0.0205 - precision: 1.0000 - recall: 0.9670 - val_loss: 1.0066 - val_accuracy: 0.8095 - val_mse: 0.1365 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.9880 - mse: 0.0192 - precision: 1.0000 - recall: 0.9780 - val_loss: 1.0008 - val_accuracy: 0.8095 - val_mse: 0.1362 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.9880 - mse: 0.0188 - precision: 1.0000 - recall: 0.9780 - val_loss: 0.9892 - val_accuracy: 0.8095 - val_mse: 0.1373 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.9819 - mse: 0.0179 - precision: 1.0000 - recall: 0.9670 - val_loss: 0.9724 - val_accuracy: 0.8095 - val_mse: 0.1366 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.9940 - mse: 0.0166 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.9530 - val_accuracy: 0.8095 - val_mse: 0.1355 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.9940 - mse: 0.0155 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.9468 - val_accuracy: 0.8095 - val_mse: 0.1365 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.9880 - mse: 0.0141 - precision: 1.0000 - recall: 0.9780 - val_loss: 0.9343 - val_accuracy: 0.8095 - val_mse: 0.1378 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.9940 - mse: 0.0138 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.9233 - val_accuracy: 0.8095 - val_mse: 0.1375 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.9940 - mse: 0.0131 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.9080 - val_accuracy: 0.8095 - val_mse: 0.1380 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 1.0000 - mse: 0.0121 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.8095 - val_mse: 0.1400 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 1.0000 - mse: 0.0117 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.9079 - val_accuracy: 0.8095 - val_mse: 0.1418 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 1.0000 - mse: 0.0115 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.8095 - val_mse: 0.1418 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.9940 - mse: 0.0115 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.9027 - val_accuracy: 0.8095 - val_mse: 0.1442 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 1.0000 - mse: 0.0106 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8803 - val_accuracy: 0.8095 - val_mse: 0.1383 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.9940 - mse: 0.0101 - precision: 1.0000 - recall: 0.9890 - val_loss: 0.8872 - val_accuracy: 0.8095 - val_mse: 0.1429 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 1.0000 - mse: 0.0098 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.8095 - val_mse: 0.1413 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 1.0000 - mse: 0.0100 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.7619 - val_mse: 0.1475 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 1.0000 - mse: 0.0092 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8530 - val_accuracy: 0.8095 - val_mse: 0.1386 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 1.0000 - mse: 0.0087 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8681 - val_accuracy: 0.7619 - val_mse: 0.1458 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 1.0000 - mse: 0.0083 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.7619 - val_mse: 0.1487 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 1.0000 - mse: 0.0085 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.8095 - val_mse: 0.1384 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 1.0000 - mse: 0.0081 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.7619 - val_mse: 0.1523 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 1.0000 - mse: 0.0088 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8758 - val_accuracy: 0.7619 - val_mse: 0.1535 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 1.0000 - mse: 0.0081 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8596 - val_accuracy: 0.7143 - val_mse: 0.1521 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 1.0000 - mse: 0.0075 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.7619 - val_mse: 0.1558 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 1.0000 - mse: 0.0074 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8650 - val_accuracy: 0.7619 - val_mse: 0.1562 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 1.0000 - mse: 0.0077 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8492 - val_accuracy: 0.7619 - val_mse: 0.1545 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 1.0000 - mse: 0.0076 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8696 - val_accuracy: 0.7619 - val_mse: 0.1591 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 1.0000 - mse: 0.0077 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.7619 - val_mse: 0.1567 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.9940 - mse: 0.0079 - precision: 0.9891 - recall: 1.0000 - val_loss: 0.8338 - val_accuracy: 0.7619 - val_mse: 0.1554 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 1.0000 - mse: 0.0072 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8657 - val_accuracy: 0.7619 - val_mse: 0.1633 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 1.0000 - mse: 0.0067 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8317 - val_accuracy: 0.7619 - val_mse: 0.1547 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 1.0000 - mse: 0.0073 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8263 - val_accuracy: 0.7619 - val_mse: 0.1549 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 1.0000 - mse: 0.0068 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8478 - val_accuracy: 0.7619 - val_mse: 0.1606 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 1.0000 - mse: 0.0064 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8394 - val_accuracy: 0.7619 - val_mse: 0.1600 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 1.0000 - mse: 0.0064 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8338 - val_accuracy: 0.7619 - val_mse: 0.1595 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 1.0000 - mse: 0.0062 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8312 - val_accuracy: 0.7619 - val_mse: 0.1584 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 1.0000 - mse: 0.0061 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.7619 - val_mse: 0.1581 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 1.0000 - mse: 0.0060 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.7619 - val_mse: 0.1526 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 1.0000 - mse: 0.0058 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.7619 - val_mse: 0.1550 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 1.0000 - mse: 0.0059 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8368 - val_accuracy: 0.7619 - val_mse: 0.1611 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 1.0000 - mse: 0.0058 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7619 - val_mse: 0.1539 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 1.0000 - mse: 0.0055 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7619 - val_mse: 0.1543 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 1.0000 - mse: 0.0059 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7619 - val_mse: 0.1554 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 1.0000 - mse: 0.0058 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.7619 - val_mse: 0.1534 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 1.0000 - mse: 0.0054 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7619 - val_mse: 0.1566 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2859 - accuracy: 1.0000 - mse: 0.0053 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7619 - val_mse: 0.1552 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 1.0000 - mse: 0.0055 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.7619 - val_mse: 0.1573 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 1.0000 - mse: 0.0055 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7619 - val_mse: 0.1523 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 1.0000 - mse: 0.0052 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7684 - val_accuracy: 0.7619 - val_mse: 0.1465 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 1.0000 - mse: 0.0054 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.7619 - val_mse: 0.1559 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 1.0000 - mse: 0.0049 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7954 - val_accuracy: 0.7619 - val_mse: 0.1545 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 1.0000 - mse: 0.0052 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.7619 - val_mse: 0.1578 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2697 - accuracy: 1.0000 - mse: 0.0049 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.7619 - val_mse: 0.1531 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2683 - accuracy: 1.0000 - mse: 0.0050 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.7619 - val_mse: 0.1486 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 1.0000 - mse: 0.0050 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.8083 - val_accuracy: 0.7619 - val_mse: 0.1591 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 1.0000 - mse: 0.0049 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.7619 - val_mse: 0.1527 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 1.0000 - mse: 0.0047 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.7619 - val_mse: 0.1551 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 1.0000 - mse: 0.0048 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7786 - val_accuracy: 0.7619 - val_mse: 0.1521 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 1.0000 - mse: 0.0046 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7820 - val_accuracy: 0.7619 - val_mse: 0.1540 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 1.0000 - mse: 0.0046 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.7619 - val_mse: 0.1565 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 1.0000 - mse: 0.0044 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7862 - val_accuracy: 0.7619 - val_mse: 0.1555 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 1.0000 - mse: 0.0044 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7793 - val_accuracy: 0.7619 - val_mse: 0.1535 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2483 - accuracy: 1.0000 - mse: 0.0044 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7735 - val_accuracy: 0.7619 - val_mse: 0.1520 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 1.0000 - mse: 0.0047 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.7619 - val_mse: 0.1541 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 1.0000 - mse: 0.0042 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.7619 - val_mse: 0.1570 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "INFO:tensorflow:Assets written to: ./model4/assets\n"
     ]
    }
   ],
   "source": [
    "fitModel(tf_model4, 'model4', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0185bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.7575 - accuracy: 0.4699 - mse: 0.2750 - precision: 0.5361 - recall: 0.5200 - val_loss: 0.7099 - val_accuracy: 0.3810 - val_mse: 0.2582 - val_precision: 0.2500 - val_recall: 0.2222\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7265 - accuracy: 0.4639 - mse: 0.2647 - precision: 0.5106 - recall: 0.5275 - val_loss: 0.7056 - val_accuracy: 0.3810 - val_mse: 0.2562 - val_precision: 0.2500 - val_recall: 0.2222\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.4277 - mse: 0.2706 - precision: 0.4783 - recall: 0.4835 - val_loss: 0.7033 - val_accuracy: 0.3810 - val_mse: 0.2550 - val_precision: 0.2500 - val_recall: 0.2222\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5301 - mse: 0.2477 - precision: 0.5684 - recall: 0.5934 - val_loss: 0.7018 - val_accuracy: 0.4286 - val_mse: 0.2543 - val_precision: 0.3333 - val_recall: 0.3333\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5361 - mse: 0.2513 - precision: 0.5795 - recall: 0.5604 - val_loss: 0.6976 - val_accuracy: 0.4762 - val_mse: 0.2522 - val_precision: 0.3750 - val_recall: 0.3333\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.5783 - mse: 0.2319 - precision: 0.6082 - recall: 0.6484 - val_loss: 0.6962 - val_accuracy: 0.3810 - val_mse: 0.2515 - val_precision: 0.3000 - val_recall: 0.3333\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.5723 - mse: 0.2445 - precision: 0.5909 - recall: 0.7143 - val_loss: 0.6980 - val_accuracy: 0.4286 - val_mse: 0.2524 - val_precision: 0.3846 - val_recall: 0.5556\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6771 - accuracy: 0.5361 - mse: 0.2430 - precision: 0.5814 - recall: 0.5495 - val_loss: 0.6970 - val_accuracy: 0.4286 - val_mse: 0.2520 - val_precision: 0.3846 - val_recall: 0.5556\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.5843 - mse: 0.2297 - precision: 0.6000 - recall: 0.7253 - val_loss: 0.6974 - val_accuracy: 0.4286 - val_mse: 0.2522 - val_precision: 0.3846 - val_recall: 0.5556\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.5843 - mse: 0.2378 - precision: 0.5948 - recall: 0.7582 - val_loss: 0.6960 - val_accuracy: 0.5238 - val_mse: 0.2515 - val_precision: 0.4615 - val_recall: 0.6667\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.5542 - mse: 0.2395 - precision: 0.5766 - recall: 0.7033 - val_loss: 0.6919 - val_accuracy: 0.5238 - val_mse: 0.2495 - val_precision: 0.4615 - val_recall: 0.6667\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.6084 - mse: 0.2362 - precision: 0.6182 - recall: 0.7473 - val_loss: 0.6909 - val_accuracy: 0.5238 - val_mse: 0.2490 - val_precision: 0.4615 - val_recall: 0.6667\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.5904 - mse: 0.2305 - precision: 0.6018 - recall: 0.7473 - val_loss: 0.6896 - val_accuracy: 0.5238 - val_mse: 0.2483 - val_precision: 0.4615 - val_recall: 0.6667\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6084 - mse: 0.2316 - precision: 0.6226 - recall: 0.7253 - val_loss: 0.6874 - val_accuracy: 0.5714 - val_mse: 0.2472 - val_precision: 0.5000 - val_recall: 0.6667\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.5904 - mse: 0.2251 - precision: 0.6018 - recall: 0.7473 - val_loss: 0.6839 - val_accuracy: 0.5714 - val_mse: 0.2455 - val_precision: 0.5000 - val_recall: 0.6667\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6687 - mse: 0.2266 - precision: 0.6698 - recall: 0.7802 - val_loss: 0.6791 - val_accuracy: 0.5714 - val_mse: 0.2431 - val_precision: 0.5000 - val_recall: 0.6667\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6205 - mse: 0.2223 - precision: 0.6273 - recall: 0.7582 - val_loss: 0.6732 - val_accuracy: 0.5714 - val_mse: 0.2401 - val_precision: 0.5000 - val_recall: 0.6667\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6446 - mse: 0.2188 - precision: 0.6404 - recall: 0.8022 - val_loss: 0.6689 - val_accuracy: 0.5714 - val_mse: 0.2380 - val_precision: 0.5000 - val_recall: 0.6667\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.6386 - mse: 0.2160 - precision: 0.6372 - recall: 0.7912 - val_loss: 0.6658 - val_accuracy: 0.5714 - val_mse: 0.2363 - val_precision: 0.5000 - val_recall: 0.6667\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6325 - mse: 0.2172 - precision: 0.6250 - recall: 0.8242 - val_loss: 0.6641 - val_accuracy: 0.5714 - val_mse: 0.2353 - val_precision: 0.5000 - val_recall: 0.6667\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6145 - mse: 0.2180 - precision: 0.6262 - recall: 0.7363 - val_loss: 0.6625 - val_accuracy: 0.6190 - val_mse: 0.2344 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6325 - mse: 0.2174 - precision: 0.6172 - recall: 0.8681 - val_loss: 0.6580 - val_accuracy: 0.6190 - val_mse: 0.2321 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.6747 - mse: 0.2032 - precision: 0.6609 - recall: 0.8352 - val_loss: 0.6486 - val_accuracy: 0.6190 - val_mse: 0.2277 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.6506 - mse: 0.2031 - precision: 0.6602 - recall: 0.7473 - val_loss: 0.6405 - val_accuracy: 0.6190 - val_mse: 0.2238 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.5843 - mse: 0.2091 - precision: 0.6078 - recall: 0.6813 - val_loss: 0.6342 - val_accuracy: 0.6190 - val_mse: 0.2208 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.6566 - mse: 0.1973 - precision: 0.6574 - recall: 0.7802 - val_loss: 0.6233 - val_accuracy: 0.6190 - val_mse: 0.2158 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6566 - mse: 0.1981 - precision: 0.6604 - recall: 0.7692 - val_loss: 0.6134 - val_accuracy: 0.6190 - val_mse: 0.2113 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.6687 - mse: 0.1948 - precision: 0.6579 - recall: 0.8242 - val_loss: 0.6063 - val_accuracy: 0.6190 - val_mse: 0.2080 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6506 - mse: 0.2044 - precision: 0.6602 - recall: 0.7473 - val_loss: 0.5983 - val_accuracy: 0.6190 - val_mse: 0.2042 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.6747 - mse: 0.1911 - precision: 0.6729 - recall: 0.7912 - val_loss: 0.5891 - val_accuracy: 0.6190 - val_mse: 0.1999 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.6325 - mse: 0.2093 - precision: 0.6500 - recall: 0.7143 - val_loss: 0.5814 - val_accuracy: 0.6190 - val_mse: 0.1963 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7048 - mse: 0.1902 - precision: 0.7019 - recall: 0.8022 - val_loss: 0.5756 - val_accuracy: 0.6190 - val_mse: 0.1936 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7108 - mse: 0.1765 - precision: 0.6903 - recall: 0.8571 - val_loss: 0.5687 - val_accuracy: 0.6190 - val_mse: 0.1904 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7289 - mse: 0.1855 - precision: 0.7091 - recall: 0.8571 - val_loss: 0.5590 - val_accuracy: 0.6190 - val_mse: 0.1866 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7349 - mse: 0.1818 - precision: 0.7156 - recall: 0.8571 - val_loss: 0.5537 - val_accuracy: 0.6190 - val_mse: 0.1840 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7169 - mse: 0.1763 - precision: 0.7157 - recall: 0.8022 - val_loss: 0.5547 - val_accuracy: 0.6190 - val_mse: 0.1838 - val_precision: 0.5455 - val_recall: 0.6667\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7349 - mse: 0.1740 - precision: 0.7282 - recall: 0.8242 - val_loss: 0.5577 - val_accuracy: 0.6667 - val_mse: 0.1838 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.6867 - mse: 0.1765 - precision: 0.6857 - recall: 0.7912 - val_loss: 0.5545 - val_accuracy: 0.6667 - val_mse: 0.1823 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7470 - mse: 0.1687 - precision: 0.7248 - recall: 0.8681 - val_loss: 0.5547 - val_accuracy: 0.6667 - val_mse: 0.1816 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.6867 - mse: 0.1869 - precision: 0.6789 - recall: 0.8132 - val_loss: 0.5493 - val_accuracy: 0.6667 - val_mse: 0.1791 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7590 - mse: 0.1557 - precision: 0.7476 - recall: 0.8462 - val_loss: 0.5477 - val_accuracy: 0.6667 - val_mse: 0.1775 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7892 - mse: 0.1517 - precision: 0.7692 - recall: 0.8791 - val_loss: 0.5471 - val_accuracy: 0.6667 - val_mse: 0.1762 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7590 - mse: 0.1638 - precision: 0.7476 - recall: 0.8462 - val_loss: 0.5404 - val_accuracy: 0.6667 - val_mse: 0.1736 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7771 - mse: 0.1445 - precision: 0.7596 - recall: 0.8681 - val_loss: 0.5417 - val_accuracy: 0.6667 - val_mse: 0.1722 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7530 - mse: 0.1667 - precision: 0.7451 - recall: 0.8352 - val_loss: 0.5410 - val_accuracy: 0.7143 - val_mse: 0.1706 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7892 - mse: 0.1419 - precision: 0.7545 - recall: 0.9121 - val_loss: 0.5284 - val_accuracy: 0.6667 - val_mse: 0.1671 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7711 - mse: 0.1456 - precision: 0.7524 - recall: 0.8681 - val_loss: 0.5077 - val_accuracy: 0.6667 - val_mse: 0.1621 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8373 - mse: 0.1247 - precision: 0.8333 - recall: 0.8791 - val_loss: 0.5083 - val_accuracy: 0.6667 - val_mse: 0.1611 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7651 - mse: 0.1508 - precision: 0.7708 - recall: 0.8132 - val_loss: 0.5052 - val_accuracy: 0.6667 - val_mse: 0.1604 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7771 - mse: 0.1506 - precision: 0.7647 - recall: 0.8571 - val_loss: 0.5108 - val_accuracy: 0.6667 - val_mse: 0.1604 - val_precision: 0.5833 - val_recall: 0.7778\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8855 - mse: 0.1038 - precision: 0.8830 - recall: 0.9121 - val_loss: 0.5180 - val_accuracy: 0.7143 - val_mse: 0.1607 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8072 - mse: 0.1318 - precision: 0.8172 - recall: 0.8352 - val_loss: 0.5117 - val_accuracy: 0.7143 - val_mse: 0.1600 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8072 - mse: 0.1361 - precision: 0.8041 - recall: 0.8571 - val_loss: 0.5103 - val_accuracy: 0.7143 - val_mse: 0.1590 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.7892 - mse: 0.1343 - precision: 0.7800 - recall: 0.8571 - val_loss: 0.5104 - val_accuracy: 0.7143 - val_mse: 0.1576 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7831 - mse: 0.1431 - precision: 0.7957 - recall: 0.8132 - val_loss: 0.5118 - val_accuracy: 0.7143 - val_mse: 0.1582 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8554 - mse: 0.1080 - precision: 0.8384 - recall: 0.9121 - val_loss: 0.5123 - val_accuracy: 0.7143 - val_mse: 0.1579 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.7711 - mse: 0.1331 - precision: 0.7524 - recall: 0.8681 - val_loss: 0.4960 - val_accuracy: 0.7143 - val_mse: 0.1554 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.7831 - mse: 0.1185 - precision: 0.7895 - recall: 0.8242 - val_loss: 0.4938 - val_accuracy: 0.7143 - val_mse: 0.1543 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8072 - mse: 0.1319 - precision: 0.7980 - recall: 0.8681 - val_loss: 0.4870 - val_accuracy: 0.7143 - val_mse: 0.1532 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8012 - mse: 0.1172 - precision: 0.8152 - recall: 0.8242 - val_loss: 0.4887 - val_accuracy: 0.7143 - val_mse: 0.1524 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8133 - mse: 0.1144 - precision: 0.8191 - recall: 0.8462 - val_loss: 0.4932 - val_accuracy: 0.7619 - val_mse: 0.1525 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8373 - mse: 0.1086 - precision: 0.8556 - recall: 0.8462 - val_loss: 0.5115 - val_accuracy: 0.7619 - val_mse: 0.1557 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8373 - mse: 0.1167 - precision: 0.8333 - recall: 0.8791 - val_loss: 0.5256 - val_accuracy: 0.7619 - val_mse: 0.1567 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8313 - mse: 0.1212 - precision: 0.8387 - recall: 0.8571 - val_loss: 0.5341 - val_accuracy: 0.7619 - val_mse: 0.1557 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8494 - mse: 0.1094 - precision: 0.8438 - recall: 0.8901 - val_loss: 0.5462 - val_accuracy: 0.7619 - val_mse: 0.1545 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8133 - mse: 0.1239 - precision: 0.8261 - recall: 0.8352 - val_loss: 0.5478 - val_accuracy: 0.7619 - val_mse: 0.1521 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8434 - mse: 0.1055 - precision: 0.8421 - recall: 0.8791 - val_loss: 0.5557 - val_accuracy: 0.7619 - val_mse: 0.1530 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8193 - mse: 0.1162 - precision: 0.8211 - recall: 0.8571 - val_loss: 0.5645 - val_accuracy: 0.7619 - val_mse: 0.1551 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8675 - mse: 0.0983 - precision: 0.8966 - recall: 0.8571 - val_loss: 0.5455 - val_accuracy: 0.7143 - val_mse: 0.1546 - val_precision: 0.6364 - val_recall: 0.7778\n",
      "INFO:tensorflow:Assets written to: ./model5/assets\n"
     ]
    }
   ],
   "source": [
    "fitModel(tf_model5, 'model5', [earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2085f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pomocna funkcia\n",
    "def predictEval(tf_model, XX, yy):\n",
    "    # vykonanie predikcie\n",
    "    y_pred = tf_model.predict(XX)\n",
    "    # uprava outputu na boolean\n",
    "    y_pred_bool = np.copy(y_pred)\n",
    "    for x in y_pred_bool:\n",
    "        x[0] = round(x[0])\n",
    "    y_pred_bool\n",
    "\n",
    "    #vratenie y a accuaracy\n",
    "    return [y_pred, y_pred_bool, accuracy_score(y_pred_bool, yy), mean_squared_error(y_pred_bool, yy), precision_score(y_pred_bool, yy), recall_score(y_pred_bool, yy)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ac23f",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56957029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictEvalWrap(model, name):\n",
    "    train = predictEval(model, X_train, y_train)\n",
    "    val = predictEval(model, X_val, y_val)\n",
    "    test = predictEval(model, X_test, y_test)\n",
    "\n",
    "    print(name)\n",
    "    print('Accuracy score')\n",
    "    print(f'Train: {train[2]*100:.2f}%')\n",
    "    print(f'Val: {val[2]*100:.2f}%')\n",
    "    print(f'Test: {test[2]*100:.2f}%')\n",
    "    print('Mean squared error')\n",
    "    print(f'Train: {train[3]*100:.2f}%')\n",
    "    print(f'Val: {val[3]*100:.2f}%')\n",
    "    print(f'Test: {test[3]*100:.2f}%')\n",
    "    print('Precision')\n",
    "    print(f'Train: {train[4]*100:.2f}%')\n",
    "    print(f'Val: {val[4]*100:.2f}%')\n",
    "    print(f'Test: {test[4]*100:.2f}%')\n",
    "    print('Recall')\n",
    "    print(f'Train: {train[5]*100:.2f}%')\n",
    "    print(f'Val: {val[5]*100:.2f}%')\n",
    "    print(f'Test: {test[5]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b444aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 621us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "No overfit prevention\n",
      "Accuracy score\n",
      "Train: 100.00%\n",
      "Val: 80.95%\n",
      "Test: 85.71%\n",
      "Mean squared error\n",
      "Train: 0.00%\n",
      "Val: 19.05%\n",
      "Test: 14.29%\n",
      "Precision\n",
      "Train: 100.00%\n",
      "Val: 88.89%\n",
      "Test: 100.00%\n",
      "Recall\n",
      "Train: 100.00%\n",
      "Val: 72.73%\n",
      "Test: 78.57%\n",
      "6/6 [==============================] - 0s 644us/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Dropout\n",
      "Accuracy score\n",
      "Train: 96.39%\n",
      "Val: 76.19%\n",
      "Test: 80.95%\n",
      "Mean squared error\n",
      "Train: 3.61%\n",
      "Val: 23.81%\n",
      "Test: 19.05%\n",
      "Precision\n",
      "Train: 97.80%\n",
      "Val: 77.78%\n",
      "Test: 81.82%\n",
      "Recall\n",
      "Train: 95.70%\n",
      "Val: 70.00%\n",
      "Test: 81.82%\n",
      "6/6 [==============================] - 0s 624us/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Early stopping\n",
      "Accuracy score\n",
      "Train: 99.40%\n",
      "Val: 71.43%\n",
      "Test: 76.19%\n",
      "Mean squared error\n",
      "Train: 0.60%\n",
      "Val: 28.57%\n",
      "Test: 23.81%\n",
      "Precision\n",
      "Train: 98.90%\n",
      "Val: 77.78%\n",
      "Test: 81.82%\n",
      "Recall\n",
      "Train: 100.00%\n",
      "Val: 63.64%\n",
      "Test: 75.00%\n",
      "6/6 [==============================] - 0s 618us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Regularization\n",
      "Accuracy score\n",
      "Train: 100.00%\n",
      "Val: 76.19%\n",
      "Test: 76.19%\n",
      "Mean squared error\n",
      "Train: 0.00%\n",
      "Val: 23.81%\n",
      "Test: 23.81%\n",
      "Precision\n",
      "Train: 100.00%\n",
      "Val: 77.78%\n",
      "Test: 81.82%\n",
      "Recall\n",
      "Train: 100.00%\n",
      "Val: 70.00%\n",
      "Test: 75.00%\n",
      "6/6 [==============================] - 0s 661us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Dropout + Early stopping\n",
      "Accuracy score\n",
      "Train: 95.18%\n",
      "Val: 71.43%\n",
      "Test: 85.71%\n",
      "Mean squared error\n",
      "Train: 4.82%\n",
      "Val: 28.57%\n",
      "Test: 14.29%\n",
      "Precision\n",
      "Train: 94.51%\n",
      "Val: 77.78%\n",
      "Test: 81.82%\n",
      "Recall\n",
      "Train: 96.63%\n",
      "Val: 63.64%\n",
      "Test: 90.00%\n"
     ]
    }
   ],
   "source": [
    "predictEvalWrap(tf_model1, 'No overfit prevention')\n",
    "predictEvalWrap(tf_model2, 'Dropout')\n",
    "predictEvalWrap(tf_model3, 'Early stopping')\n",
    "predictEvalWrap(tf_model4, 'Regularization')\n",
    "predictEvalWrap(tf_model5, 'Dropout + Early stopping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a688b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f17a7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch model\n",
    "class PyTorchModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PyTorchModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c7c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchModelDropout(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.5):\n",
    "        super(PyTorchModelDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 16)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(16, 16)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d7e8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65da1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SonarDataset(X_train, y_train)\n",
    "val_dataset = SonarDataset(X_val, y_val)\n",
    "test_dataset = SonarDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06616cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "input_dim = len(X_train.columns)\n",
    "model = PyTorchModel(input_dim)\n",
    "model_dropout = PyTorchModelDropout(input_dim, dropout_rate=0.5)\n",
    "model_early_stopping = PyTorchModel(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1b6f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "optimizer_dropout = optim.Adam(model_dropout.parameters())\n",
    "optimizer_early_stopping = optim.Adam(model_early_stopping.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8d03d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9157ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 0.6699, Val Loss: 0.7054\n",
      "Epoch: 2/100, Loss: 0.6647, Val Loss: 0.7053\n",
      "Epoch: 3/100, Loss: 0.6119, Val Loss: 0.7057\n",
      "Epoch: 4/100, Loss: 0.6692, Val Loss: 0.7072\n",
      "Epoch: 5/100, Loss: 0.7123, Val Loss: 0.7063\n",
      "Epoch: 6/100, Loss: 0.5804, Val Loss: 0.6995\n",
      "Epoch: 7/100, Loss: 0.6390, Val Loss: 0.6928\n",
      "Epoch: 8/100, Loss: 0.4733, Val Loss: 0.6733\n",
      "Epoch: 9/100, Loss: 0.3155, Val Loss: 0.6403\n",
      "Epoch: 10/100, Loss: 0.4065, Val Loss: 0.6010\n",
      "Epoch: 11/100, Loss: 0.3615, Val Loss: 0.5622\n",
      "Epoch: 12/100, Loss: 0.3025, Val Loss: 0.5231\n",
      "Epoch: 13/100, Loss: 0.1330, Val Loss: 0.5041\n",
      "Epoch: 14/100, Loss: 0.1786, Val Loss: 0.4923\n",
      "Epoch: 15/100, Loss: 0.3210, Val Loss: 0.5097\n",
      "Epoch: 16/100, Loss: 0.0179, Val Loss: 0.5094\n",
      "Epoch: 17/100, Loss: 0.1601, Val Loss: 0.5293\n",
      "Epoch: 18/100, Loss: 0.0622, Val Loss: 0.5465\n",
      "Epoch: 19/100, Loss: 0.3940, Val Loss: 0.5480\n",
      "Epoch: 20/100, Loss: 0.0724, Val Loss: 0.5812\n",
      "Epoch: 21/100, Loss: 0.2850, Val Loss: 0.6137\n",
      "Epoch: 22/100, Loss: 0.1049, Val Loss: 0.6154\n",
      "Epoch: 23/100, Loss: 0.0436, Val Loss: 0.6472\n",
      "Epoch: 24/100, Loss: 0.0758, Val Loss: 0.6837\n",
      "Epoch: 25/100, Loss: 0.0096, Val Loss: 0.7104\n",
      "Epoch: 26/100, Loss: 0.0149, Val Loss: 0.7129\n",
      "Epoch: 27/100, Loss: 0.0918, Val Loss: 0.6985\n",
      "Epoch: 28/100, Loss: 0.0053, Val Loss: 0.7230\n",
      "Epoch: 29/100, Loss: 0.0058, Val Loss: 0.7423\n",
      "Epoch: 30/100, Loss: 0.0111, Val Loss: 0.7629\n",
      "Epoch: 31/100, Loss: 0.0408, Val Loss: 0.7661\n",
      "Epoch: 32/100, Loss: 0.0000, Val Loss: 0.7775\n",
      "Epoch: 33/100, Loss: 0.0275, Val Loss: 0.8043\n",
      "Epoch: 34/100, Loss: 0.0149, Val Loss: 0.8041\n",
      "Epoch: 35/100, Loss: 0.0078, Val Loss: 0.8146\n",
      "Epoch: 36/100, Loss: 0.0006, Val Loss: 0.8290\n",
      "Epoch: 37/100, Loss: 0.0119, Val Loss: 0.8582\n",
      "Epoch: 38/100, Loss: 0.0044, Val Loss: 0.8792\n",
      "Epoch: 39/100, Loss: 0.0040, Val Loss: 0.8903\n",
      "Epoch: 40/100, Loss: 0.0071, Val Loss: 0.8958\n",
      "Epoch: 41/100, Loss: 0.0112, Val Loss: 0.9055\n",
      "Epoch: 42/100, Loss: 0.0051, Val Loss: 0.9160\n",
      "Epoch: 43/100, Loss: 0.0074, Val Loss: 0.9122\n",
      "Epoch: 44/100, Loss: 0.0073, Val Loss: 0.9246\n",
      "Epoch: 45/100, Loss: 0.0011, Val Loss: 0.9356\n",
      "Epoch: 46/100, Loss: 0.0003, Val Loss: 0.9459\n",
      "Epoch: 47/100, Loss: 0.0017, Val Loss: 0.9512\n",
      "Epoch: 48/100, Loss: 0.0033, Val Loss: 0.9632\n",
      "Epoch: 49/100, Loss: 0.0083, Val Loss: 0.9784\n",
      "Epoch: 50/100, Loss: 0.0023, Val Loss: 0.9795\n",
      "Epoch: 51/100, Loss: 0.0034, Val Loss: 0.9793\n",
      "Epoch: 52/100, Loss: 0.0002, Val Loss: 0.9894\n",
      "Epoch: 53/100, Loss: 0.0010, Val Loss: 0.9990\n",
      "Epoch: 54/100, Loss: 0.0004, Val Loss: 1.0130\n",
      "Epoch: 55/100, Loss: 0.0003, Val Loss: 1.0204\n",
      "Epoch: 56/100, Loss: 0.0017, Val Loss: 1.0266\n",
      "Epoch: 57/100, Loss: 0.0034, Val Loss: 1.0404\n",
      "Epoch: 58/100, Loss: 0.0017, Val Loss: 1.0469\n",
      "Epoch: 59/100, Loss: 0.0029, Val Loss: 1.0546\n",
      "Epoch: 60/100, Loss: 0.0000, Val Loss: 1.0572\n",
      "Epoch: 61/100, Loss: 0.0004, Val Loss: 1.0607\n",
      "Epoch: 62/100, Loss: 0.0008, Val Loss: 1.0687\n",
      "Epoch: 63/100, Loss: 0.0000, Val Loss: 1.0867\n",
      "Epoch: 64/100, Loss: 0.0007, Val Loss: 1.0946\n",
      "Epoch: 65/100, Loss: 0.0006, Val Loss: 1.1014\n",
      "Epoch: 66/100, Loss: 0.0001, Val Loss: 1.1059\n",
      "Epoch: 67/100, Loss: 0.0016, Val Loss: 1.1058\n",
      "Epoch: 68/100, Loss: 0.0012, Val Loss: 1.1124\n",
      "Epoch: 69/100, Loss: 0.0000, Val Loss: 1.1222\n",
      "Epoch: 70/100, Loss: 0.0004, Val Loss: 1.1243\n",
      "Epoch: 71/100, Loss: 0.0004, Val Loss: 1.1349\n",
      "Epoch: 72/100, Loss: 0.0002, Val Loss: 1.1348\n",
      "Epoch: 73/100, Loss: 0.0007, Val Loss: 1.1440\n",
      "Epoch: 74/100, Loss: 0.0009, Val Loss: 1.1441\n",
      "Epoch: 75/100, Loss: 0.0008, Val Loss: 1.1463\n",
      "Epoch: 76/100, Loss: 0.0011, Val Loss: 1.1459\n",
      "Epoch: 77/100, Loss: 0.0003, Val Loss: 1.1560\n",
      "Epoch: 78/100, Loss: 0.0005, Val Loss: 1.1569\n",
      "Epoch: 79/100, Loss: 0.0003, Val Loss: 1.1577\n",
      "Epoch: 80/100, Loss: 0.0000, Val Loss: 1.1595\n",
      "Epoch: 81/100, Loss: 0.0001, Val Loss: 1.1743\n",
      "Epoch: 82/100, Loss: 0.0005, Val Loss: 1.1752\n",
      "Epoch: 83/100, Loss: 0.0005, Val Loss: 1.1778\n",
      "Epoch: 84/100, Loss: 0.0000, Val Loss: 1.1775\n",
      "Epoch: 85/100, Loss: 0.0003, Val Loss: 1.1790\n",
      "Epoch: 86/100, Loss: 0.0005, Val Loss: 1.1992\n",
      "Epoch: 87/100, Loss: 0.0001, Val Loss: 1.2005\n",
      "Epoch: 88/100, Loss: 0.0003, Val Loss: 1.2008\n",
      "Epoch: 89/100, Loss: 0.0000, Val Loss: 1.2024\n",
      "Epoch: 90/100, Loss: 0.0003, Val Loss: 1.2046\n",
      "Epoch: 91/100, Loss: 0.0003, Val Loss: 1.2048\n",
      "Epoch: 92/100, Loss: 0.0011, Val Loss: 1.2050\n",
      "Epoch: 93/100, Loss: 0.0002, Val Loss: 1.2047\n",
      "Epoch: 94/100, Loss: 0.0005, Val Loss: 1.2087\n",
      "Epoch: 95/100, Loss: 0.0007, Val Loss: 1.2446\n",
      "Epoch: 96/100, Loss: 0.0002, Val Loss: 1.2454\n",
      "Epoch: 97/100, Loss: 0.0001, Val Loss: 1.2462\n",
      "Epoch: 98/100, Loss: 0.0002, Val Loss: 1.2471\n",
      "Epoch: 99/100, Loss: 0.0001, Val Loss: 1.2489\n",
      "Epoch: 100/100, Loss: 0.0002, Val Loss: 1.2492\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            y_val_pred = model(X_val_batch)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89725875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 0.6915, Val Loss: 0.6941\n",
      "Epoch: 2/100, Loss: 0.6863, Val Loss: 0.6941\n",
      "Epoch: 3/100, Loss: 0.6853, Val Loss: 0.6941\n",
      "Epoch: 4/100, Loss: 0.7485, Val Loss: 0.6941\n",
      "Epoch: 5/100, Loss: 0.6858, Val Loss: 0.6941\n",
      "Epoch: 6/100, Loss: 0.6753, Val Loss: 0.6941\n",
      "Epoch: 7/100, Loss: 0.6941, Val Loss: 0.6941\n",
      "Epoch: 8/100, Loss: 0.6825, Val Loss: 0.6941\n",
      "Epoch: 9/100, Loss: 0.6948, Val Loss: 0.6941\n",
      "Epoch: 10/100, Loss: 0.6802, Val Loss: 0.6941\n",
      "Epoch: 11/100, Loss: 0.7008, Val Loss: 0.6941\n",
      "Epoch: 12/100, Loss: 0.6922, Val Loss: 0.6941\n",
      "Epoch: 13/100, Loss: 0.6346, Val Loss: 0.6941\n",
      "Epoch: 14/100, Loss: 0.6850, Val Loss: 0.6941\n",
      "Epoch: 15/100, Loss: 0.7035, Val Loss: 0.6941\n",
      "Epoch: 16/100, Loss: 0.6729, Val Loss: 0.6941\n",
      "Epoch: 17/100, Loss: 0.7157, Val Loss: 0.6941\n",
      "Epoch: 18/100, Loss: 0.6800, Val Loss: 0.6941\n",
      "Epoch: 19/100, Loss: 0.6833, Val Loss: 0.6941\n",
      "Epoch: 20/100, Loss: 0.6715, Val Loss: 0.6941\n",
      "Epoch: 21/100, Loss: 0.7234, Val Loss: 0.6941\n",
      "Epoch: 22/100, Loss: 0.6930, Val Loss: 0.6941\n",
      "Epoch: 23/100, Loss: 0.6654, Val Loss: 0.6941\n",
      "Epoch: 24/100, Loss: 0.7116, Val Loss: 0.6941\n",
      "Epoch: 25/100, Loss: 0.6469, Val Loss: 0.6941\n",
      "Epoch: 26/100, Loss: 0.7260, Val Loss: 0.6941\n",
      "Epoch: 27/100, Loss: 0.6861, Val Loss: 0.6941\n",
      "Epoch: 28/100, Loss: 0.6968, Val Loss: 0.6941\n",
      "Epoch: 29/100, Loss: 0.6583, Val Loss: 0.6941\n",
      "Epoch: 30/100, Loss: 0.7423, Val Loss: 0.6941\n",
      "Epoch: 31/100, Loss: 0.7083, Val Loss: 0.6941\n",
      "Epoch: 32/100, Loss: 0.7055, Val Loss: 0.6941\n",
      "Epoch: 33/100, Loss: 0.7465, Val Loss: 0.6941\n",
      "Epoch: 34/100, Loss: 0.7460, Val Loss: 0.6941\n",
      "Epoch: 35/100, Loss: 0.6723, Val Loss: 0.6941\n",
      "Epoch: 36/100, Loss: 0.6937, Val Loss: 0.6941\n",
      "Epoch: 37/100, Loss: 0.7013, Val Loss: 0.6941\n",
      "Epoch: 38/100, Loss: 0.7013, Val Loss: 0.6941\n",
      "Epoch: 39/100, Loss: 0.6553, Val Loss: 0.6941\n",
      "Epoch: 40/100, Loss: 0.7474, Val Loss: 0.6941\n",
      "Epoch: 41/100, Loss: 0.6248, Val Loss: 0.6941\n",
      "Epoch: 42/100, Loss: 0.6906, Val Loss: 0.6941\n",
      "Epoch: 43/100, Loss: 0.6920, Val Loss: 0.6941\n",
      "Epoch: 44/100, Loss: 0.7152, Val Loss: 0.6941\n",
      "Epoch: 45/100, Loss: 0.7396, Val Loss: 0.6941\n",
      "Epoch: 46/100, Loss: 0.6529, Val Loss: 0.6941\n",
      "Epoch: 47/100, Loss: 0.6968, Val Loss: 0.6941\n",
      "Epoch: 48/100, Loss: 0.6858, Val Loss: 0.6941\n",
      "Epoch: 49/100, Loss: 0.6795, Val Loss: 0.6941\n",
      "Epoch: 50/100, Loss: 0.6770, Val Loss: 0.6941\n",
      "Epoch: 51/100, Loss: 0.6889, Val Loss: 0.6941\n",
      "Epoch: 52/100, Loss: 0.7095, Val Loss: 0.6941\n",
      "Epoch: 53/100, Loss: 0.7386, Val Loss: 0.6941\n",
      "Epoch: 54/100, Loss: 0.6527, Val Loss: 0.6941\n",
      "Epoch: 55/100, Loss: 0.6513, Val Loss: 0.6941\n",
      "Epoch: 56/100, Loss: 0.7231, Val Loss: 0.6941\n",
      "Epoch: 57/100, Loss: 0.7418, Val Loss: 0.6941\n",
      "Epoch: 58/100, Loss: 0.7297, Val Loss: 0.6941\n",
      "Epoch: 59/100, Loss: 0.7182, Val Loss: 0.6941\n",
      "Epoch: 60/100, Loss: 0.6467, Val Loss: 0.6941\n",
      "Epoch: 61/100, Loss: 0.6518, Val Loss: 0.6941\n",
      "Epoch: 62/100, Loss: 0.7160, Val Loss: 0.6941\n",
      "Epoch: 63/100, Loss: 0.7001, Val Loss: 0.6941\n",
      "Epoch: 64/100, Loss: 0.6781, Val Loss: 0.6941\n",
      "Epoch: 65/100, Loss: 0.6988, Val Loss: 0.6941\n",
      "Epoch: 66/100, Loss: 0.6917, Val Loss: 0.6941\n",
      "Epoch: 67/100, Loss: 0.7115, Val Loss: 0.6941\n",
      "Epoch: 68/100, Loss: 0.6872, Val Loss: 0.6941\n",
      "Epoch: 69/100, Loss: 0.6946, Val Loss: 0.6941\n",
      "Epoch: 70/100, Loss: 0.7220, Val Loss: 0.6941\n",
      "Epoch: 71/100, Loss: 0.7332, Val Loss: 0.6941\n",
      "Epoch: 72/100, Loss: 0.6771, Val Loss: 0.6941\n",
      "Epoch: 73/100, Loss: 0.6690, Val Loss: 0.6941\n",
      "Epoch: 74/100, Loss: 0.6782, Val Loss: 0.6941\n",
      "Epoch: 75/100, Loss: 0.7223, Val Loss: 0.6941\n",
      "Epoch: 76/100, Loss: 0.6932, Val Loss: 0.6941\n",
      "Epoch: 77/100, Loss: 0.6908, Val Loss: 0.6941\n",
      "Epoch: 78/100, Loss: 0.6768, Val Loss: 0.6941\n",
      "Epoch: 79/100, Loss: 0.6568, Val Loss: 0.6941\n",
      "Epoch: 80/100, Loss: 0.6656, Val Loss: 0.6941\n",
      "Epoch: 81/100, Loss: 0.5681, Val Loss: 0.6941\n",
      "Epoch: 82/100, Loss: 0.6806, Val Loss: 0.6941\n",
      "Epoch: 83/100, Loss: 0.7066, Val Loss: 0.6941\n",
      "Epoch: 84/100, Loss: 0.7208, Val Loss: 0.6941\n",
      "Epoch: 85/100, Loss: 0.6915, Val Loss: 0.6941\n",
      "Epoch: 86/100, Loss: 0.7060, Val Loss: 0.6941\n",
      "Epoch: 87/100, Loss: 0.6365, Val Loss: 0.6941\n",
      "Epoch: 88/100, Loss: 0.7172, Val Loss: 0.6941\n",
      "Epoch: 89/100, Loss: 0.6806, Val Loss: 0.6941\n",
      "Epoch: 90/100, Loss: 0.6848, Val Loss: 0.6941\n",
      "Epoch: 91/100, Loss: 0.6737, Val Loss: 0.6941\n",
      "Epoch: 92/100, Loss: 0.7416, Val Loss: 0.6941\n",
      "Epoch: 93/100, Loss: 0.7463, Val Loss: 0.6941\n",
      "Epoch: 94/100, Loss: 0.7424, Val Loss: 0.6941\n",
      "Epoch: 95/100, Loss: 0.6831, Val Loss: 0.6941\n",
      "Epoch: 96/100, Loss: 0.6705, Val Loss: 0.6941\n",
      "Epoch: 97/100, Loss: 0.6541, Val Loss: 0.6941\n",
      "Epoch: 98/100, Loss: 0.6681, Val Loss: 0.6941\n",
      "Epoch: 99/100, Loss: 0.7382, Val Loss: 0.6941\n",
      "Epoch: 100/100, Loss: 0.6830, Val Loss: 0.6941\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model_dropout.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer_dropout.zero_grad()\n",
    "        y_pred = model_dropout(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_dropout.eval()\n",
    "        val_loss_sum = 0\n",
    "        val_batch_count = 0\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            y_val_pred = model_dropout(X_val_batch)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_loss_sum += val_loss.item()\n",
    "            val_batch_count += 1\n",
    "        val_loss_avg = val_loss_sum / val_batch_count\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfabdcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 0.6456, Val Loss: 0.7059\n",
      "Epoch: 2/100, Loss: 0.6719, Val Loss: 0.7059\n",
      "Epoch: 3/100, Loss: 0.6455, Val Loss: 0.7059\n",
      "Epoch: 4/100, Loss: 0.6965, Val Loss: 0.7059\n",
      "Epoch: 5/100, Loss: 0.6986, Val Loss: 0.7059\n",
      "Epoch: 6/100, Loss: 0.6428, Val Loss: 0.7059\n",
      "Epoch: 7/100, Loss: 0.6971, Val Loss: 0.7059\n",
      "Epoch: 8/100, Loss: 0.6970, Val Loss: 0.7059\n",
      "Epoch: 9/100, Loss: 0.6705, Val Loss: 0.7059\n",
      "Epoch: 10/100, Loss: 0.6937, Val Loss: 0.7059\n",
      "Epoch: 11/100, Loss: 0.6694, Val Loss: 0.7059\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "patience = 10\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_early_stopping.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer_early_stopping.zero_grad()\n",
    "        y_pred = model_early_stopping(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_early_stopping.eval()\n",
    "        val_loss_sum = 0\n",
    "        val_batch_count = 0\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            y_val_pred = model_early_stopping(X_val_batch)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_loss_sum += val_loss.item()\n",
    "            val_batch_count += 1\n",
    "        val_loss_avg = val_loss_sum / val_batch_count\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss_avg:.4f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss_avg < best_val_loss:\n",
    "        best_val_loss = val_loss_avg\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ab49a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_eval(model, loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            y_pred_bool = torch.round(y_pred)\n",
    "            accuracy = accuracy_score(y_pred_bool, y_batch)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce38c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = predict_eval(model, train_loader)\n",
    "val_accuracy = predict_eval(model, val_loader)\n",
    "test_accuracy = predict_eval(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55ec5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_dropout = predict_eval(model_dropout, train_loader)\n",
    "val_accuracy_dropout = predict_eval(model_dropout, val_loader)\n",
    "test_accuracy_dropout = predict_eval(model_dropout, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1da69398",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_early_stopping = predict_eval(model_early_stopping, train_loader)\n",
    "val_accuracy_early_stopping = predict_eval(model_early_stopping, val_loader)\n",
    "test_accuracy_early_stopping = predict_eval(model_early_stopping, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5df66fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overfit prevention\n",
      "Train: 100.00%\n",
      "Val: 66.67%\n",
      "Test: 71.43%\n"
     ]
    }
   ],
   "source": [
    "print('No overfit prevention')\n",
    "print(f'Train: {train_accuracy * 100:.2f}%')\n",
    "print(f'Val: {val_accuracy * 100:.2f}%')\n",
    "print(f'Test: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26db5e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Droupout\n",
      "Train: 33.33%\n",
      "Val: 57.14%\n",
      "Test: 47.62%\n"
     ]
    }
   ],
   "source": [
    "print('Droupout')\n",
    "print(f'Train: {train_accuracy_dropout * 100:.2f}%')\n",
    "print(f'Val: {val_accuracy_dropout * 100:.2f}%')\n",
    "print(f'Test: {test_accuracy_dropout * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36cee445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Train: 16.67%\n",
      "Val: 42.86%\n",
      "Test: 52.38%\n"
     ]
    }
   ],
   "source": [
    "print('Early stopping')\n",
    "print(f'Train: {train_accuracy_early_stopping * 100:.2f}%')\n",
    "print(f'Val: {val_accuracy_early_stopping * 100:.2f}%')\n",
    "print(f'Test: {test_accuracy_early_stopping * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0dc699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161de969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
